{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "\n",
    "from helper_functions import train_or_load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load shadow model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the shadow model trained in the other python script\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # sets to gpu if you have one\n",
    "\n",
    "mobilenet_shadow =  models.mobilenet_v2(pretrained=False,num_classes=10)\n",
    "mobilenet_shadow.load_state_dict(torch.load(\"shadow_models/mobilenet_shadow_cifar_overtrained.pth\",map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'pickle/cifar10/mobilenetv2/shadow.p'\n",
    "# Change the DATA_PATH to your local pickle file path\n",
    "\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "\n",
    "#splitting\n",
    "#only use train set here\n",
    "train_data, val_data = train_test_split(dataset, test_size=(1-0.5),shuffle=False)\n",
    "  \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False, num_workers=2)\n",
    "testloader =  torch.utils.data.DataLoader(val_data, batch_size=1, shuffle=True, num_workers=2)\n",
    "\n",
    "for batch_idx, (img, label) in enumerate(train_loader):\n",
    "    img = img.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Attack model Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset for attack model\n",
    "mobilenet_shadow.eval()\n",
    "dataset_attack = []\n",
    "# NON Members\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader: #need only one\n",
    "            # Move images and labels to the appropriate device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "        logits = mobilenet_shadow(images)\n",
    "        #take the 3 biggest logist\n",
    "        top_values = torch.topk(logits, k=3).values\n",
    "        top_values, indices = torch.sort(top_values, dim=1, descending=True)\n",
    "        dataset_attack.append([top_values,0])\n",
    "# MEMBERS\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader: #need only one\n",
    "            # Move images and labels to the appropriate device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "        logits = mobilenet_shadow(images)\n",
    "        #take the 3 biggest logist\n",
    "        top_values = torch.topk(logits, k=3).values\n",
    "        top_values, indices = torch.sort(top_values, dim=1, descending=True)\n",
    "        dataset_attack.append([top_values,1])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Convert all tensors to the same dtype first\\ntensors = [data[0].float() for data in dataset_attack]  # Ensure all tensors are Float type\\nall_data = torch.cat(tensors, dim=0)  # Concatenate all tensors\\n\\n# Calculate mean and std\\nmean = all_data.mean(dim=0)\\nstd = all_data.std(dim=0)\\n\\n# Standardize data in the list\\nstandardized_data_list = [( (data[0] - mean) / std, data[1] ) for data in dataset_attack]\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_data_list = dataset_attack\n",
    "\n",
    "# # Convert all tensors to the same dtype first\n",
    "# tensors = [data[0].float() for data in dataset_attack]  # Ensure all tensors are Float type\n",
    "# all_data = torch.cat(tensors, dim=0)  # Concatenate all tensors\n",
    "\n",
    "# # Calculate mean and std\n",
    "# mean = all_data.mean(dim=0)\n",
    "# std = all_data.std(dim=0)\n",
    "\n",
    "# # Standardize data in the list\n",
    "# standardized_data_list = [( (data[0] - mean) / std, data[1] ) for data in dataset_attack]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dataloader = torch.utils.data.DataLoader(standardized_data_list, batch_size=64, shuffle=True, num_workers=2) #shuffled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)\n",
    "        self.fc5 = nn.Linear(16, 8)\n",
    "        self.bn5 = nn.BatchNorm1d(8)\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(torch.relu(self.bn5(self.fc5(x))))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_model = SimpleNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(attack_model.parameters(), lr=0.0001)\n",
    "attack_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inputs in attack_dataloader:\n",
    "#     inputs = inputs[0]\n",
    "#     print(inputs.shape)  # Check input shape consistenc\n",
    "#     print(inputs)\n",
    "#     print(inputs)\n",
    "#     outputs = attack_model(inputs.squeeze(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001743FBD1DA0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1436, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7569, 0.5706, 0.4115]])\n",
      "tensor([0.])\n",
      "Batch 0 with Loss: 0.6691667437553406\n",
      "tensor([[0.3281, 0.2959, 0.2014]])\n",
      "tensor([0.])\n",
      "Batch 30 with Loss: 0.7166800498962402\n",
      "tensor([[0.4421, 0.2805, 0.2435]])\n",
      "tensor([1.])\n",
      "Batch 60 with Loss: 0.6952509880065918\n",
      "tensor([[0.6007, 0.5285, 0.3627]])\n",
      "tensor([1.])\n",
      "Batch 90 with Loss: 0.7080126404762268\n",
      "tensor([[1.4218, 1.2167, 0.9277]])\n",
      "tensor([1.])\n",
      "Batch 120 with Loss: 0.7215996980667114\n",
      "tensor([[0.5054, 0.4674, 0.3625]])\n",
      "tensor([0.])\n",
      "Batch 150 with Loss: 0.6880431175231934\n",
      "tensor([[0.5406, 0.1882, 0.1676]])\n",
      "tensor([0.])\n",
      "Batch 180 with Loss: 0.7156131267547607\n",
      "tensor([[0.3323, 0.2286, 0.2144]])\n",
      "tensor([1.])\n",
      "Batch 210 with Loss: 0.700903594493866\n",
      "tensor([[0.3211, 0.1837, 0.0598]])\n",
      "tensor([0.])\n",
      "Batch 240 with Loss: 0.6900610327720642\n",
      "tensor([[0.4039, 0.3599, 0.3435]])\n",
      "tensor([0.])\n",
      "Batch 270 with Loss: 0.6937681436538696\n",
      "tensor([[0.2097, 0.1341, 0.1272]])\n",
      "tensor([1.])\n",
      "Batch 300 with Loss: 0.6926522850990295\n",
      "tensor([[0.5366, 0.4885, 0.4006]])\n",
      "tensor([0.])\n",
      "Batch 330 with Loss: 0.6948705911636353\n",
      "tensor([[ 0.3606,  0.2521, -0.0009]])\n",
      "tensor([1.])\n",
      "Batch 360 with Loss: 0.6979615688323975\n",
      "tensor([[1.7221, 1.2230, 0.6143]])\n",
      "tensor([0.])\n",
      "Batch 390 with Loss: 0.707363486289978\n",
      "tensor([[0.5272, 0.5038, 0.3977]])\n",
      "tensor([1.])\n",
      "Batch 420 with Loss: 0.7021462917327881\n",
      "tensor([[0.4652, 0.3528, 0.2634]])\n",
      "tensor([1.])\n",
      "Batch 450 with Loss: 0.6834245920181274\n",
      "Epoch: 2\n",
      "tensor([[0.4025, 0.3049, 0.1512]])\n",
      "tensor([0.])\n",
      "Batch 0 with Loss: 0.7166284918785095\n",
      "tensor([[0.8644, 0.7013, 0.6111]])\n",
      "tensor([1.])\n",
      "Batch 30 with Loss: 0.7082335352897644\n",
      "tensor([[0.7029, 0.5605, 0.3486]])\n",
      "tensor([1.])\n",
      "Batch 60 with Loss: 0.7001063823699951\n",
      "tensor([[0.3919, 0.2611, 0.1969]])\n",
      "tensor([1.])\n",
      "Batch 90 with Loss: 0.7069023251533508\n",
      "tensor([[0.3633, 0.2327, 0.1314]])\n",
      "tensor([0.])\n",
      "Batch 120 with Loss: 0.704575777053833\n",
      "tensor([[0.7263, 0.4942, 0.4423]])\n",
      "tensor([0.])\n",
      "Batch 150 with Loss: 0.701738715171814\n",
      "tensor([[0.8515, 0.7142, 0.6246]])\n",
      "tensor([0.])\n",
      "Batch 180 with Loss: 0.6931319832801819\n",
      "tensor([[0.6311, 0.5519, 0.2208]])\n",
      "tensor([1.])\n",
      "Batch 210 with Loss: 0.7066950798034668\n",
      "tensor([[0.4881, 0.3506, 0.2485]])\n",
      "tensor([0.])\n",
      "Batch 240 with Loss: 0.7261402606964111\n",
      "tensor([[0.6478, 0.4519, 0.2498]])\n",
      "tensor([0.])\n",
      "Batch 270 with Loss: 0.7149988412857056\n",
      "tensor([[0.5735, 0.3777, 0.1234]])\n",
      "tensor([0.])\n",
      "Batch 300 with Loss: 0.7156869173049927\n",
      "tensor([[1.2824, 0.6279, 0.4761]])\n",
      "tensor([0.])\n",
      "Batch 330 with Loss: 0.6914538145065308\n",
      "tensor([[0.6245, 0.3695, 0.2709]])\n",
      "tensor([0.])\n",
      "Batch 360 with Loss: 0.6769697666168213\n",
      "tensor([[0.5406, 0.1882, 0.1676]])\n",
      "tensor([0.])\n",
      "Batch 390 with Loss: 0.683952808380127\n",
      "tensor([[0.3810, 0.2364, 0.2347]])\n",
      "tensor([0.])\n",
      "Batch 420 with Loss: 0.6842689514160156\n",
      "tensor([[0.6762, 0.4741, 0.4303]])\n",
      "tensor([0.])\n",
      "Batch 450 with Loss: 0.7229477763175964\n",
      "Epoch: 3\n",
      "tensor([[0.6242, 0.3925, 0.3911]])\n",
      "tensor([1.])\n",
      "Batch 0 with Loss: 0.687397837638855\n",
      "tensor([[0.5714, 0.3572, 0.0734]])\n",
      "tensor([0.])\n",
      "Batch 30 with Loss: 0.7008744478225708\n",
      "tensor([[0.2810, 0.2689, 0.1439]])\n",
      "tensor([1.])\n",
      "Batch 60 with Loss: 0.7144739031791687\n",
      "tensor([[0.4544, 0.4173, 0.3733]])\n",
      "tensor([0.])\n",
      "Batch 90 with Loss: 0.6913147568702698\n",
      "tensor([[0.2231, 0.1123, 0.1070]])\n",
      "tensor([0.])\n",
      "Batch 120 with Loss: 0.6945180892944336\n",
      "tensor([[0.4789, 0.4506, 0.4495]])\n",
      "tensor([1.])\n",
      "Batch 150 with Loss: 0.71222984790802\n",
      "tensor([[0.4310, 0.2173, 0.0849]])\n",
      "tensor([1.])\n",
      "Batch 180 with Loss: 0.706932783126831\n",
      "tensor([[0.4579, 0.3787, 0.2589]])\n",
      "tensor([1.])\n",
      "Batch 210 with Loss: 0.6764115691184998\n",
      "tensor([[ 0.3660,  0.2805, -0.0244]])\n",
      "tensor([1.])\n",
      "Batch 240 with Loss: 0.691632866859436\n",
      "tensor([[0.5037, 0.4718, 0.4241]])\n",
      "tensor([0.])\n",
      "Batch 270 with Loss: 0.7086505889892578\n",
      "tensor([[0.4616, 0.3024, 0.0307]])\n",
      "tensor([1.])\n",
      "Batch 300 with Loss: 0.6926831603050232\n",
      "tensor([[0.3042, 0.3021, 0.1583]])\n",
      "tensor([1.])\n",
      "Batch 330 with Loss: 0.707651674747467\n",
      "tensor([[0.3295, 0.1916, 0.0873]])\n",
      "tensor([0.])\n",
      "Batch 360 with Loss: 0.7038450241088867\n",
      "tensor([[0.4927, 0.3641, 0.1978]])\n",
      "tensor([0.])\n",
      "Batch 390 with Loss: 0.6741986274719238\n",
      "tensor([[0.2326, 0.1398, 0.1367]])\n",
      "tensor([1.])\n",
      "Batch 420 with Loss: 0.7100002765655518\n",
      "tensor([[0.4288, 0.3961, 0.3012]])\n",
      "tensor([0.])\n",
      "Batch 450 with Loss: 0.7059887051582336\n",
      "Epoch: 4\n",
      "tensor([[0.1637, 0.0713, 0.0465]])\n",
      "tensor([0.])\n",
      "Batch 0 with Loss: 0.7027719020843506\n",
      "tensor([[0.2382, 0.2288, 0.1861]])\n",
      "tensor([1.])\n",
      "Batch 30 with Loss: 0.7123593688011169\n",
      "tensor([[0.3846, 0.2783, 0.2291]])\n",
      "tensor([1.])\n",
      "Batch 60 with Loss: 0.6919981837272644\n",
      "tensor([[0.2463, 0.2262, 0.2212]])\n",
      "tensor([0.])\n",
      "Batch 90 with Loss: 0.7109522223472595\n",
      "tensor([[0.6957, 0.3965, 0.3661]])\n",
      "tensor([1.])\n",
      "Batch 120 with Loss: 0.6889559030532837\n",
      "tensor([[0.2933, 0.2160, 0.2153]])\n",
      "tensor([1.])\n",
      "Batch 150 with Loss: 0.7106753587722778\n",
      "tensor([[0.3998, 0.2993, 0.1540]])\n",
      "tensor([1.])\n",
      "Batch 180 with Loss: 0.6933160424232483\n",
      "tensor([[0.4222, 0.3556, 0.2709]])\n",
      "tensor([1.])\n",
      "Batch 210 with Loss: 0.6877927780151367\n",
      "tensor([[0.3246, 0.3098, 0.1900]])\n",
      "tensor([1.])\n",
      "Batch 240 with Loss: 0.6980000734329224\n",
      "tensor([[0.6897, 0.6484, 0.4852]])\n",
      "tensor([0.])\n",
      "Batch 270 with Loss: 0.6866079568862915\n",
      "tensor([[0.4959, 0.4882, 0.3840]])\n",
      "tensor([0.])\n",
      "Batch 300 with Loss: 0.6919688582420349\n",
      "tensor([[1.6441, 0.5561, 0.4495]])\n",
      "tensor([1.])\n",
      "Batch 330 with Loss: 0.7134054899215698\n",
      "tensor([[0.5542, 0.1660, 0.0887]])\n",
      "tensor([1.])\n",
      "Batch 360 with Loss: 0.7070083618164062\n",
      "tensor([[0.8503, 0.4282, 0.3256]])\n",
      "tensor([1.])\n",
      "Batch 390 with Loss: 0.6835322380065918\n",
      "tensor([[0.3455, 0.3023, 0.2655]])\n",
      "tensor([1.])\n",
      "Batch 420 with Loss: 0.6819968223571777\n",
      "tensor([[0.3924, 0.1696, 0.1373]])\n",
      "tensor([1.])\n",
      "Batch 450 with Loss: 0.7091236114501953\n",
      "Epoch: 5\n",
      "tensor([[0.1799, 0.1641, 0.1271]])\n",
      "tensor([0.])\n",
      "Batch 0 with Loss: 0.7012073993682861\n",
      "tensor([[0.7620, 0.5732, 0.0871]])\n",
      "tensor([1.])\n",
      "Batch 30 with Loss: 0.6899377703666687\n",
      "tensor([[0.3756, 0.3390, 0.2556]])\n",
      "tensor([0.])\n",
      "Batch 60 with Loss: 0.7173981666564941\n",
      "tensor([[0.7507, 0.7355, 0.3627]])\n",
      "tensor([1.])\n",
      "Batch 90 with Loss: 0.7028363943099976\n",
      "tensor([[0.3666, 0.2981, 0.2156]])\n",
      "tensor([0.])\n",
      "Batch 120 with Loss: 0.692562997341156\n",
      "tensor([[0.7493, 0.6373, 0.3368]])\n",
      "tensor([0.])\n",
      "Batch 150 with Loss: 0.6884260773658752\n",
      "tensor([[0.4907, 0.4440, 0.3915]])\n",
      "tensor([0.])\n",
      "Batch 180 with Loss: 0.7007836699485779\n",
      "tensor([[0.7011, 0.5856, 0.3431]])\n",
      "tensor([0.])\n",
      "Batch 210 with Loss: 0.7058506608009338\n",
      "tensor([[1.4793, 1.0474, 0.8965]])\n",
      "tensor([0.])\n",
      "Batch 240 with Loss: 0.7076427340507507\n",
      "tensor([[0.7907, 0.7421, 0.6131]])\n",
      "tensor([1.])\n",
      "Batch 270 with Loss: 0.6856281757354736\n",
      "tensor([[0.1780, 0.1734, 0.1342]])\n",
      "tensor([0.])\n",
      "Batch 300 with Loss: 0.6920356750488281\n",
      "tensor([[0.3326, 0.2422, 0.1115]])\n",
      "tensor([1.])\n",
      "Batch 330 with Loss: 0.6873858571052551\n",
      "tensor([[0.4252, 0.3077, 0.0235]])\n",
      "tensor([0.])\n",
      "Batch 360 with Loss: 0.7004943490028381\n",
      "tensor([[0.3149, 0.1474, 0.0886]])\n",
      "tensor([0.])\n",
      "Batch 390 with Loss: 0.6953285336494446\n",
      "tensor([[0.3767, 0.3234, 0.2722]])\n",
      "tensor([1.])\n",
      "Batch 420 with Loss: 0.7034428119659424\n",
      "tensor([[0.3191, 0.1236, 0.1121]])\n",
      "tensor([1.])\n",
      "Batch 450 with Loss: 0.6968066096305847\n"
     ]
    }
   ],
   "source": [
    "train_or_load(attack_model,attack_dataloader,optimizer,criterion,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(attack_model.state_dict(), 'attack_models/attack_mobilenet_cifar.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"pickle/cifar10/mobilenetv2/eval.p\"\n",
    "\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "# Convert all tensors to the same dtype first\n",
    "\n",
    "eval_data_loader = torch.utils.data.DataLoader(dataset, batch_size=1 , shuffle=False, num_workers=2)\n",
    "#splitting\n",
    "for batch_idx, (img, label, membership) in enumerate(eval_data_loader):\n",
    "    img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_target_model =  models.mobilenet_v2(weights=None,num_classes=10)\n",
    "check = torch.load(\"models/mobilenetv2_cifar10.pth\", map_location=device)\n",
    "# check[\"net\"][\"classifier.0.weight\"]=check[\"net\"].pop(\"classifier.1.weight\")\n",
    "# check[\"net\"][\"classifier.0.bias\"]=check[\"net\"].pop(\"classifier.1.bias\")\n",
    "\n",
    "resnet_target_model.load_state_dict(check[\"net\"])\n",
    "resnet_target_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get posteriors from target\n",
    "dataset_eval = []\n",
    "with torch.no_grad():\n",
    "    for images,_, member in eval_data_loader: # take only image for query and member status (ignore cifar label)\n",
    "            # Move images and labels to the appropriate device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "        logits = resnet_target_model(images)\n",
    "        \n",
    "        #take the 3 biggest logist\n",
    "        top_values = torch.topk(logits, k=3).values #order poseri\n",
    "        sorted_tensor, indices = torch.sort(top_values, dim=1,descending=True)\n",
    "        dataset_eval.append([sorted_tensor, member.item()])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_eval\n",
    "# # Convert all tensors to the same dtype first\n",
    "# tensors = [data[0].float() for data in dataset_eval]  # Ensure all tensors are Float type\n",
    "# all_data = torch.cat(tensors, dim=0)  # Concatenate all tensors\n",
    "\n",
    "# # Calculate mean and std\n",
    "# mean = all_data.mean(dim=0)\n",
    "# std = all_data.std(dim=0)\n",
    "\n",
    "# # Standardize data in the list\n",
    "# dataset = [( (data[0] - mean) / std, data[1] ) for data in dataset_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_eval = torch.utils.data.DataLoader(dataset, batch_size=1 , shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "def evaluate_attack_model(model, train_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for sorted_logits, members in train_loader:\n",
    "            sorted_logits = sorted_logits.float()\n",
    "            #labels = torch.tensor(labels[0])\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(sorted_logits.squeeze(dim=1))\n",
    "            predicted = torch.round(outputs)  # Round the outputs to 0 or 1\n",
    "            total += members.size(0)  # Increment the total count by batch size\n",
    "            correct += (predicted == members).sum().item()  # Count correct predictions\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "accuracy = evaluate_attack_model(attack_model, dataloader_eval)#\n",
    "\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
