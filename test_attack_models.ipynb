{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import isfile\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet34, mobilenet_v2\n",
    "from helper_functions import DatasetClassN, standardize_dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Attack model paths\n",
    "attackmodel_paths = [\n",
    "    # 'attack_models/attack_mobilenet_tinyimage.pth',\n",
    "    # 'attack_models/attack_mobilenet_cifar.pth',\n",
    "    'attack_models/attack_resnet_cifar.pth',\n",
    "    # 'attack_models/attack_resnet_tinyimage.pth'\n",
    "]\n",
    "standardize = [\n",
    "    # False,\n",
    "    # False,\n",
    "    False,\n",
    "    # False\n",
    "]\n",
    "# Parameters\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # sets to gpu if you have one\n",
    "MULTI_TREAD_N = 1\n",
    "NUM_LOGITS = 3\n",
    "print (DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load attack models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(32)  # Matches the output of fc1\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)  # Matches the output of fc2\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)  # Matches the output of fc3\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)  # Matches the output of fc4\n",
    "        self.fc5 = nn.Linear(16, 8)\n",
    "        self.bn5 = nn.BatchNorm1d(8)   # Matches the output of fc5\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(torch.relu(self.bn5(self.fc5(x))))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "def loat_target_model (module:nn.Module, target_model_type:str, dset_type:str)->nn.Module:\n",
    "    targetmodel_p = 'models/' + f'{target_model_type}_{dset_type}.pth'\n",
    "    assert isfile(targetmodel_p), \"Targetmodel path \\\"{targetmodel_p}\\n not found!\"\n",
    "    module.load_state_dict(torch.load(targetmodel_p, map_location=DEVICE)[\"net\"])\n",
    "    return module\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attack_target_model (attack_model_p:str)->tuple[nn.Module, nn.Module, str, str]:\n",
    "    assert isfile(attack_model_p), f'Attackmodel path \\\"{attack_model_p}\\\" not found!'\n",
    "    # Read model type and dataset type from filename\n",
    "    att_m_name = attack_model_p.split(\"/\")[1].split(\".\")[0].split(\"_\")\n",
    "    target_model_type = att_m_name[1]\n",
    "    dset_type = att_m_name[2]\n",
    "    # Load attack model\n",
    "    state_dict = torch.load(attack_model_p, map_location=DEVICE)\n",
    "    attck_model = AttackNN ()\n",
    "    attck_model.load_state_dict(state_dict)    \n",
    "    # Get correct model modules and dataset names\n",
    "    if dset_type == \"cifar\":\n",
    "        dset_type = \"cifar10\"\n",
    "        # Get correct classnumber for dataset\n",
    "        n_c = DatasetClassN.Cifar.value\n",
    "    elif dset_type == \"tinyimage\":\n",
    "        dset_type = \"tinyimagenet\"\n",
    "        n_c = DatasetClassN.Tinyimage.value\n",
    "    else:\n",
    "        raise ValueError(f'{dset_type} not valid dataset type string.')\n",
    "    # Get correct pytorch model module\n",
    "    if target_model_type == \"mobilenet\":\n",
    "        target_model_module = mobilenet_v2(weights=None, num_classes=n_c)\n",
    "        target_model_type = \"mobilenetv2\"\n",
    "    elif target_model_type == \"resnet\":\n",
    "        target_model_module = resnet34 (weights=None, num_classes=n_c)\n",
    "        target_model_type = \"resnet34\"\n",
    "    else:\n",
    "        raise ValueError(f'{target_model_type} not valid model type string.')\n",
    "    # Load correct statedict into target model\n",
    "    target_model = loat_target_model (target_model_module, target_model_type, dset_type)\n",
    "    return attck_model, target_model, target_model_type, dset_type\n",
    "\n",
    "def get_posterior_dl (target_m:nn.Module, test_datal:DataLoader, num_logits:int, multi_thr_n:int, standardize:bool=False):\n",
    "    target_m.eval()\n",
    "    post_list = []\n",
    "    with torch.no_grad():\n",
    "        for image, _ in test_datal: # take only image for query and member status (ignore cifar label)\n",
    "            # Move images and labels to the appropriate DEVICE\n",
    "            # image.to(DEVICE)\n",
    "            # Forward pass\n",
    "            logits = target_m(image.squeeze(1))\n",
    "            #take the 3 biggest logist\n",
    "            top_values = torch.topk(logits, k=num_logits).values #order poseri\n",
    "            sorted_tensor, _ = torch.sort(top_values, dim=1,descending=True)\n",
    "            post_list.append(sorted_tensor)\n",
    "    # Standardize\n",
    "    if standardize:\n",
    "        print (\"Standarization\")\n",
    "        post_list = standardize_dset(post_list)\n",
    "    else:\n",
    "        print (\"No Standarization\")\n",
    "    return DataLoader(post_list,batch_size=1, shuffle=False, num_workers=multi_thr_n)\n",
    "\n",
    "def load_test_dataloader (target_model_type:str, dset_type:str, multi_thr_n:int)->DataLoader:\n",
    "    picklepath = 'pickle/' + f'{dset_type}/'+ f'{target_model_type}/test.p'\n",
    "    assert isfile(picklepath), f'Dataset path \\\"{picklepath}\\\" not found!'\n",
    "    with open(picklepath,\"rb\") as test_dat_f:\n",
    "        dset_l = pickle.load(test_dat_f)\n",
    "        return DataLoader(dset_l,batch_size=1, shuffle=False, num_workers=multi_thr_n), len(dset_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Evaluating attack model \"attack_mobilenet_tinyimage.pth\"!\n"
=======
      "Evaluating attack model \"attack_resnet_tinyimage.pth\"!\n",
      "Getting posteriors!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gleb\\AppData\\Local\\Temp\\ipykernel_19936\\2320093108.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions[i] = torch.round(pred).detach().numpy()\n"
>>>>>>> 443c94118b19b1d7bf24822797ff18327b937f37
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Getting posteriors!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_eval_post_loader() got an unexpected keyword argument 'num_logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Let targetmodel give its posteriors on dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting posteriors!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m target_m_post_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_eval_post_loader\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_model_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_LOGITS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Init np array with number of test.p samples\u001b[39;00m\n\u001b[1;32m     11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((sample_n), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: create_eval_post_loader() got an unexpected keyword argument 'num_logits'"
=======
      "Saving predictions at test_results/task2_resnet34_tinyimagenet.npy! The array has shape (20000,)\n",
      "[0 1 0 ... 1 0 1]\n",
      "\n"
>>>>>>> 443c94118b19b1d7bf24822797ff18327b937f37
     ]
    }
   ],
   "source": [
    "# Go through all attack models in list\n",
    "for attack_model_p, standardize_bool in attackmodel_paths, standardize_dset:\n",
    "    print (f'Evaluating attack model \\\"{attack_model_p.split(\"/\")[1]}\\\"!')\n",
    "    attack_model, target_model, target_model_type, dset_type = load_attack_target_model(attack_model_p)\n",
    "    # Load test.p for the correcto model\n",
    "    test_dataloader, sample_n = load_test_dataloader(target_model_type, dset_type, multi_thr_n=MULTI_TREAD_N)\n",
    "    # Let targetmodel give its posteriors on dataset\n",
    "    print (\"Getting posteriors!\")\n",
    "    target_m_post_dataloader = get_posterior_dl (target_model, attack_model_p, test_dataloader, num_logits=NUM_LOGITS,multi_thr_n=MULTI_TREAD_N,standardize=standardize_bool)\n",
    "    # Init np array with number of test.p samples\n",
    "    predictions = np.full((sample_n), fill_value=-1, dtype=int)\n",
    "    # Loop through posterior dataset\n",
    "    for i, sample in enumerate(target_m_post_dataloader):\n",
    "        attack_model.eval()\n",
    "        # Try to predict (non) member\n",
    "        pred = attack_model(sample.squeeze(1))\n",
    "        predictions[i] = torch.round(pred).detach().numpy()\n",
    "    # Save np prediction array\n",
    "    match target_model_type, dset_type:\n",
    "        case \"resnet34\", \"cifar10\":\n",
    "            task_num = 0\n",
    "        case \"mobilenetv2\", \"cifar10\":\n",
    "            task_num = 1\n",
    "        case \"resnet34\", \"tinyimagenet\":\n",
    "            task_num = 2\n",
    "        case \"mobilenetv2\", \"tinyimagenet\":\n",
    "            task_num = 3\n",
    "    # Save np array under correct task name\n",
    "    prediction_save_p = f'test_results/task{task_num}_{target_model_type}_{dset_type}.npy'\n",
    "    print (f\"Saving predictions at {prediction_save_p}! The array has shape {predictions.shape}\")\n",
    "    print (predictions)\n",
    "    print ()\n",
    "    np.save(prediction_save_p, predictions)\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
