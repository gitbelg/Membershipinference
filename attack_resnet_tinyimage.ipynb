{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: I did not work on this notebook, as the model seems to work fine! - Gleb\n",
    "#load the shadow model trained in the other python script\n",
    "device = \"cpu\"\n",
    "resnet_shadow = resnet34(pretrained = False,num_classes = 200).to(device) #resnet_target is the shadow model\n",
    "resnet_cifar = torch.load(\"shadow_models/resnet34_shadow_tinyimage_overtrained.pth\",map_location=torch.device('cpu'))\n",
    "resnet_shadow.load_state_dict(resnet_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'pickle/tinyimagenet/resnet34/shadow.p'\n",
    "# Change the DATA_PATH to your local pickle file path\n",
    "\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "\n",
    "#splitting\n",
    "#only use train set here\n",
    "train_data, val_data = train_test_split(dataset, test_size=(1-0.5),shuffle=False)\n",
    "  \n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=\n",
    "     1 , shuffle=False, num_workers=2)\n",
    "testloader =  torch.utils.data.DataLoader(val_data, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "for batch_idx, (img, label) in enumerate(dataloader):\n",
    "    img = img.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset for attack model\n",
    "resnet_shadow.eval()\n",
    "dataset_attack = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader: #need only one\n",
    "            # Move images and labels to the appropriate device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "        logits = resnet_shadow(images)\n",
    "        \n",
    "        #take the 3 biggest logist\n",
    "        \n",
    "        top_values = torch.topk(logits, k=3).values\n",
    "        top_values, indices = torch.sort(top_values, dim=1, descending=True)\n",
    "        dataset_attack.append([top_values,0])\n",
    "        \n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader: #need only one\n",
    "            # Move images and labels to the appropriate device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "        logits = resnet_shadow(images)\n",
    "        \n",
    "        #take the 3 biggest logist\n",
    "        \n",
    "        top_values = torch.topk(logits, k=3).values\n",
    "        top_values, indices = torch.sort(top_values, dim=1, descending=True)\n",
    "\n",
    "        dataset_attack.append([top_values,1])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert all tensors to the same dtype first\n",
    "tensors = [data[0].float() for data in dataset_attack]  # Ensure all tensors are Float type\n",
    "all_data = torch.cat(tensors, dim=0)  # Concatenate all tensors\n",
    "\n",
    "# Calculate mean and std\n",
    "mean = all_data.mean(dim=0)\n",
    "std = all_data.std(dim=0)\n",
    "\n",
    "# Standardize data in the list\n",
    "standardized_data_list = [( (data[0] - mean) / std, data[1] ) for data in dataset_attack]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_attack = torch.utils.data.DataLoader(\n",
    "    \n",
    "    standardized_data_list, batch_size=32, shuffle=True, num_workers=2) #shuffled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(32)  # Matches the output of fc1\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)  # Matches the output of fc2\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)  # Matches the output of fc3\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)  # Matches the output of fc4\n",
    "        self.fc5 = nn.Linear(16, 8)\n",
    "        self.bn5 = nn.BatchNorm1d(8)   # Matches the output of fc5\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(torch.relu(self.bn5(self.fc5(x))))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your training function\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.float()  # Ensures input tensors are floats\n",
    "        labels = labels.float().view(-1, 1)  # Ensures labels are floats and reshaped correctly\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.squeeze(dim = 1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict =  torch.load('attack_model.pth_3', map_location='cpu')\n",
    "#model.load_state_dict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "train(model,dataloader_attack,optimizer,criterion,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'attack_models/attack_resnet_tinyimage.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"eval.p\"\n",
    "\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "# Convert all tensors to the same dtype first\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=1 , shuffle=False, num_workers=2)\n",
    "#splitting\n",
    "for batch_idx, (img, label, membership) in enumerate(dataloader):\n",
    "    img = img.to(device)\n",
    "\n",
    "\n",
    "# Define your evaluation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "resnet_shadow.eval()\n",
    "with torch.no_grad():\n",
    "    for images,_, b in dataloader: #need only one\n",
    "            # Move images and labels to the appropriate device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "        logits = resnet_shadow(images)\n",
    "        print(logits)\n",
    "        \n",
    "        #take the 3 biggest logist\n",
    "        \n",
    "        top_values = torch.topk(logits, k=3).values\n",
    "        \n",
    "\n",
    "        dataset.append([top_values,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_target_model = resnet34(pretrained = False,num_classes = 200).to(device)\n",
    "check = torch.load(\"models/resnet34_tinyimagenet.pth\", map_location=torch.device('cpu'))\n",
    "resnet_target_model.load_state_dict(check[\"net\"])\n",
    "resnet_target_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get posteriors from target\n",
    "dataset_eval = []\n",
    "with torch.no_grad():\n",
    "    for images,_, member in dataloader: #need only one\n",
    "            # Move images and labels to the appropriate device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "        logits = resnet_target_model(images)\n",
    "        \n",
    "        #take the 3 biggest logist\n",
    "        \n",
    "        top_values = torch.topk(logits, k=3).values #order poseri\n",
    "        sorted_tensor, indices = torch.sort(top_values, dim=1,descending=True)\n",
    "        dataset_eval.append([sorted_tensor, member.item()])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all tensors to the same dtype first\n",
    "tensors = [data[0].float() for data in dataset_eval]  # Ensure all tensors are Float type\n",
    "all_data = torch.cat(tensors, dim=0)  # Concatenate all tensors\n",
    "\n",
    "# Calculate mean and std\n",
    "mean = all_data.mean(dim=0)\n",
    "std = all_data.std(dim=0)\n",
    "\n",
    "# Standardize data in the list\n",
    "dataset = [( (data[0] - mean) / std, data[1] ) for data in dataset_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_eval = torch.utils.data.DataLoader(\n",
    "    # TODO: make variables less convoluted\n",
    "    dataset, batch_size=1 , shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5658/100979714.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[1.]]) tensor([1.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[1.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[1.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "tensor([[0.]]) tensor([0.])\n",
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data in dataloader:\n",
    "            inputs = data[0]\n",
    "            \n",
    "            labels = data[1].float()\n",
    "            labels = torch.tensor(labels).float()\n",
    "            #labels = torch.tensor(labels[0])\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs.squeeze(dim=1))\n",
    "            predicted = torch.round(outputs)  # Round the outputs to 0 or 1\n",
    "            #predicted = abs(predicted -1)\n",
    "            print(predicted,labels)\n",
    "\n",
    "            total += labels.size(0)  # Increment the total count by batch size\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Assuming you have a DataLoader called 'test_loader' for evaluation\n",
    "# Create an instance of your model\n",
    "\n",
    "# Assuming 'test_loader' is your DataLoader for evaluation\n",
    "accuracy = evaluate(model, dataloader_eval)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - 0.26 = 0.74 > 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
