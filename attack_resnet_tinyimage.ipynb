{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet34\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper_functions import train_or_load_and_eval_atck_model, create_eval_post_loader, create_shadow_post_train_loader, evaluate_attack_model, DatasetClassN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameter\n",
    "model = \"resnet34\"\n",
    "model_short = \"resnet\"\n",
    "MODEL_MODULE = resnet34\n",
    "# Dataset parameter\n",
    "dataset = \"tinyimagenet\"\n",
    "dataset_short = \"tinyimage\"\n",
    "DATASET_ENUM = DatasetClassN.Tinyimage\n",
    "\n",
    "## Attack model training parameters\n",
    "LEARNING_R = 0.0005\n",
    "EPOCHS = 4\n",
    "MULTI_WORKERS_N = 4\n",
    "STANDARDIZE = False\n",
    "\n",
    "## Datasets\n",
    "SHADOW_DATA_PATH = f\"pickle/{dataset}/{model}/shadow.p\"\n",
    "EVALUATE_DATA_PATH = f\"pickle/{dataset}/{model}/eval.p\"\n",
    "# Save Dset create for attack model training\n",
    "ATT_TRAIN_DATA_PATH = f\"pickle/{dataset}/{model}/attack_train.p\"\n",
    "## Models\n",
    "SHADOW_MODEL_PATH = f\"shadow_models/{model}_shadow_{dataset_short}_overtrained.pth\"\n",
    "TARGET_MODEL_PATH = f\"models/{model}_{dataset}.pth\"\n",
    "ATTACK_MODEL_PATH = f\"attack_models/attack_{model_short}_{dataset_short}.pth\"\n",
    "\n",
    "DEVICE=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shadow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the shadow model trained in the other python script\n",
    "shadow_model = MODEL_MODULE(weights=None,num_classes=DATASET_ENUM.value).to(DEVICE) #resnet_target is the shadow model\n",
    "shadow_model.load_state_dict(torch.load(SHADOW_MODEL_PATH, map_location=DEVICE))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shadow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SHADOW_DATA_PATH, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "shadow_memb_data, shadow_non_memb_data = train_test_split(dataset, test_size=(1-0.5),shuffle=False)\n",
    "  \n",
    "shadow_membloader = DataLoader(shadow_memb_data, batch_size=1, shuffle=False, num_workers=1)\n",
    "shadow_non_membloader =  DataLoader(shadow_non_memb_data, batch_size=1, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Attack model training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack dataset was already established previosly, loading dataset from \"pickle/tinyimagenet/resnet34/attack_train.p\".\n"
     ]
    }
   ],
   "source": [
    "attack_train_loader = create_shadow_post_train_loader(shadow_non_membloader, shadow_membloader, shadow_model, batch_size=64, \\\n",
    "    multi_n= MULTI_WORKERS_N, data_class=DATASET_ENUM, device=DEVICE, save_path=ATT_TRAIN_DATA_PATH, standardize=STANDARDIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[4.5469, 3.7791, 2.6790,  ..., 0.0000, 0.0000, 0.0000]],  [[7.1512, 5.1823, 5.0751,  ..., 0.0000, 0.0000, 0.0000]],  [[5.2813, 4.7101, 4.1920,  ..., 0.0000, 0.0000, 0.0000]],  ...,  [[8.4213, 6.4895, 5.9865,  ..., 0.0000, 0.0000, 0.0000]],  [[7.4869, 7.3635, 5.8359,  ..., 0.0000, 0.0000, 0.0000]],  [[4.1578, 4.1452, 3.4111,  ..., 0.0000, 0.0000, 0.0000]]]), tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,  0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,  1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "attack_sample_iter = iter(attack_train_loader)\n",
    "print (str(next(attack_sample_iter)).replace('\\n',\"\").replace(\"   \",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallAttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallAttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.sigmoid(self.fc2(self.fc1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle Size Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleAttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiddleAttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(203, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.fc5 = nn.Linear(32, 16)\n",
    "        self.bn5 = nn.BatchNorm1d(16)\n",
    "        self.fc6 = nn.Linear(16, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(torch.relu(self.bn5(self.fc5(x))))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target model\n",
    "target_model = MODEL_MODULE(weights=None,num_classes=DATASET_ENUM.value)\n",
    "target_model.load_state_dict (torch.load (TARGET_MODEL_PATH, map_location=DEVICE)[\"net\"])\n",
    "target_model.eval()\n",
    "target_model.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load **Evaluation Dataset** & get Posteriors/ Member Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------SAMPLE WINDOW---------------------------------------------------------\n",
      "Number Samples: 200\n",
      "Batchsize: 1\n",
      "Inputs:tensor([[[[0.3490, 0.7451, 0.2863,  ..., 0.6275, 0.6235, 0.6157], [0.7647, 0.7569, 0.6118,  ..., 0.6196, 0.5804, 0.5882], [0.6824, 0.5569, 0.6980,  ..., 0.6588, 0.6627, 0.6863], ..., [0.6431, 0.6588, 0.5765,  ..., 0.6863, 0.5961, 0.4078], [0.7490, 0.7255, 0.7020,  ..., 0.6000, 0.5804, 0.7961], [0.7098, 0.7333, 0.6941,  ..., 0.5686, 0.7098, 0.5843]],[[0.3490, 0.7451, 0.2863,  ..., 0.6118, 0.6078, 0.6000], [0.7647, 0.7569, 0.6118,  ..., 0.6039, 0.5647, 0.5725], [0.6824, 0.5569, 0.6980,  ..., 0.6431, 0.6353, 0.6588], ..., [0.6471, 0.6627, 0.5804,  ..., 0.6902, 0.6000, 0.4118], [0.7529, 0.7294, 0.7059,  ..., 0.6039, 0.5843, 0.8000], [0.7137, 0.7373, 0.6980,  ..., 0.5725, 0.7137, 0.5882]],[[0.3098, 0.7059, 0.2471,  ..., 0.5765, 0.5647, 0.5569], [0.7255, 0.7176, 0.5725,  ..., 0.5686, 0.5216, 0.5294], [0.6510, 0.5255, 0.6667,  ..., 0.6000, 0.5961, 0.6196], ..., [0.6235, 0.6392, 0.5569,  ..., 0.6706, 0.5804, 0.3922], [0.7294, 0.7059, 0.6824,  ..., 0.5843, 0.5647, 0.7804], [0.6902, 0.7137, 0.6745,  ..., 0.5529, 0.6941, 0.5686]]]])\n",
      "Labels:tensor([1])\n",
      "Outputs:tensor([[ 4.1506e-01,1.9747e+00,2.0967e+00,3.8476e-01,1.6010e+00,4.4646e-01, -9.5463e-01,1.3563e+00,2.5413e+00,1.8399e+00,2.3325e+00,5.4841e-01,3.9890e-01, -4.1512e-01,7.1167e-02,2.0390e+00,1.2245e+01,1.3324e+00, -5.1903e-01,8.6363e-01,1.8585e+00,2.6033e-01,1.4593e+00, -1.4187e+00,1.5338e-03, -1.8409e+00,2.8611e-01,1.2099e+00, -6.0103e-01, -3.9632e-02, -4.1906e-01, -1.6818e-02, -1.2014e+00, -5.5371e-01, -1.1128e+00, -1.2915e-01,2.3689e+00,2.0131e+00,1.9221e+00,5.6394e-01,8.9722e-01,2.1176e+00,1.0194e+00, -7.9682e-01,2.0068e-01,1.5083e+00,2.7617e+00,1.1708e+00, -1.3420e-01, -2.8676e-01,1.5748e+00,1.2667e+00, -6.9970e-02, -1.4387e+00,1.3175e+00,1.7757e+00,1.5838e+00, -4.1115e-01,1.5954e+00, -8.5561e-01, -5.2405e-01, -1.8872e+00, -6.7681e-01,3.8029e-01, -6.4567e-01, -9.0297e-01,6.1002e-01, -1.1432e+00,2.0750e-01, -2.1322e-01, -1.4455e+00,9.3108e-01, -3.5625e-01,2.9288e-01, -9.9074e-01, -1.4659e+00,9.1800e-02,9.0225e-01, -3.4797e-01,2.5448e-01, -5.3741e-01, -2.5141e-01, -1.1566e+00, -9.8465e-01, -1.0785e-01,1.5923e+00, -1.0184e+00, -1.7543e-01,2.8597e-01, -8.5062e-01, -6.4088e-01, -1.2306e-01, -3.4506e-01, -1.9284e-01, -8.4094e-01, -9.0969e-01, -1.2903e+00, -1.8959e+00,2.3651e-01, -3.4006e-01, -1.2155e+00, -1.2804e+00, -1.1640e+00,2.0134e+00, -7.9242e-01, -1.0297e+00,7.2239e-01, -1.4318e+00, -1.0387e+00, -4.1486e-02, -6.3282e-01, -2.7594e-01, -2.3271e+00, -1.0596e+00, -3.5983e-01,4.9235e-01, -1.6071e+00,1.7613e-01,2.8692e-01, -6.0024e-01,1.2490e-01, -8.6397e-01,1.0596e+00, -1.9807e+00, -8.1847e-01, -2.2391e-01, -1.0792e+00, -1.4121e+00,4.1866e-02, -1.0711e+00, -5.0668e-01,1.1383e+00, -6.3977e-01,1.5004e-01,4.6466e-01, -7.8341e-01, -6.3240e-01,5.0871e-01, -6.0786e-02,4.9785e-01,4.1053e-01, -4.4802e-01, -1.7891e+00, -2.8992e-01, -2.4345e-01, -7.0110e-01, -1.3297e+00, -3.2921e-01,6.3364e-01,1.0078e-01, -1.5809e+00,4.5377e-01,3.1427e-01, -1.0656e+00, -5.4817e-01, -3.4757e-01, -6.1023e-01, -2.6978e-01,1.9052e+00,9.0489e-01, -2.7367e-01, -1.3252e+00,1.2854e+00, -1.3432e+00, -5.4960e-01, -1.7338e+00, -1.5716e+00, -1.5204e+00, -9.2117e-02, -1.4874e+00, -7.4881e-01, -7.7707e-01, -1.4898e+00, -1.1723e+00,1.2992e+00,1.1445e+00, -1.2097e+00, -1.3754e+00, -1.1300e+00, -1.4460e+00, -6.0804e-01, -2.4223e-01,6.5221e-01, -1.0811e+00, -1.2985e-02, -5.7380e-02,1.7423e+00,7.9163e-01,7.3401e-01,1.1809e+00, -8.1618e-01, -1.4295e+00, -4.5817e-02,2.4633e-01, -5.0629e-01,5.8077e-01,1.2396e+00, -6.9975e-01,5.7399e-01,1.8388e+00]])\n",
      "One hot:tensor([[12.2449,  2.7617,  2.5413,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000]])\n",
      "Top Sigmoids: tensor([[12.2449,  2.7617,  2.5413]])\n",
      "---------------------------------------------------------------------------\n",
      "No Standarization\n"
     ]
    }
   ],
   "source": [
    "with open(EVALUATE_DATA_PATH, \"rb\") as eval_f:\n",
    "    eval_dataset = pickle.load(eval_f)\n",
    "    # Create Posteriors with target model; MULTI_WORKERS_N defines workers num of returned DL\n",
    "    attack_eval_post_loader = create_eval_post_loader (target_model, eval_dataset, MULTI_WORKERS_N, data_class=DATASET_ENUM, device=DEVICE, test_dataset=False, standardize=STANDARDIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attack Evaluation DL Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[12.2449,  2.7617,  2.5413,  ...,  0.0000,  0.0000,  0.0000]],  [[12.0375,  3.2163,  2.8674,  ...,  0.0000,  0.0000,  0.0000]],  [[12.4965,  3.8211,  3.8029,  ...,  0.0000,  0.0000,  0.0000]],  ...,  [[12.4299,  3.2814,  3.1813,  ...,  0.0000,  0.0000,  0.0000]],  [[11.9616,  2.6851,  2.6250,  ...,  0.0000,  0.0000,  0.0000]],  [[12.3340,  3.3248,  3.3173,  ...,  0.0000,  0.0000,  0.0000]]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "eval_sample_iter = iter(attack_eval_post_loader)\n",
    "print (str(next(eval_sample_iter)).replace('\\n',\"\").replace(\"   \",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "------SAMPLE WINDOW---------------------------------------------------------\n",
      "Number Samples: 50000\n",
      "Batchsize: 64\n",
      "Inputs:tensor([[[5.6507, 4.6983, 4.2671,  ..., 0.0000, 0.0000, 0.0000]],  [[4.3756, 4.2527, 4.1302,  ..., 0.0000, 0.0000, 0.0000]],  [[5.8888, 5.4302, 5.3477,  ..., 0.0000, 0.0000, 0.0000]],  ...,  [[6.7200, 5.4962, 5.2476,  ..., 0.0000, 0.0000, 0.0000]],  [[4.0174, 3.6449, 2.5542,  ..., 0.0000, 0.0000, 0.0000]],  [[8.1297, 7.9380, 7.2542,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "Squeezed Input: tensor([[5.6507, 4.6983, 4.2671,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [4.3756, 4.2527, 4.1302,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [5.8888, 5.4302, 5.3477,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [6.7200, 5.4962, 5.2476,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [4.0174, 3.6449, 2.5542,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [8.1297, 7.9380, 7.2542,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Labels:tensor([[1.],[1.],[1.],[1.],[0.],[0.],[1.],[0.],[1.],[1.],[1.],[0.],[1.],[1.],[1.],[1.],[1.],[1.],[0.],[1.],[1.],[0.],[0.],[1.],[0.],[0.],[0.],[0.],[1.],[1.],[0.],[0.],[1.],[0.],[0.],[0.],[0.],[1.],[1.],[1.],[1.],[0.],[1.],[0.],[0.],[0.],[1.],[1.],[0.],[1.],[0.],[0.],[1.],[1.],[1.],[0.],[0.],[0.],[0.],[0.],[1.],[0.],[0.],[0.]])\n",
      "Outputs:tensor([[0.5441],[0.6262],[0.4354],[0.5441],[0.5122],[0.4695],[0.5282],[0.5614],[0.4144],[0.6345],[0.5561],[0.5632],[0.3534],[0.3357],[0.4292],[0.4956],[0.5035],[0.5265],[0.3651],[0.5336],[0.1800],[0.5781],[0.4203],[0.5450],[0.4208],[0.4025],[0.4773],[0.3411],[0.3286],[0.5130],[0.5236],[0.4514],[0.5351],[0.5071],[0.5883],[0.5107],[0.5520],[0.6124],[0.5949],[0.4957],[0.4920],[0.4220],[0.4354],[0.3597],[0.5403],[0.2872],[0.5774],[0.5867],[0.1644],[0.3273],[0.5595],[0.4593],[0.6427],[0.1905],[0.5585],[0.3754],[0.3720],[0.5086],[0.5642],[0.5776],[0.8147],[0.6389],[0.5148],[0.5021]], grad_fn=<SigmoidBackward0>)\n",
      "Loss:0.6989123821258545\n",
      "---------------------------------------------------------------------------\n",
      "Epoch Loss: 0.7009936491775512\n",
      "Accuracy: 0.82 with Correct: 165 and Total: 200\n",
      "Epoch: 2\n",
      "Epoch Loss: 0.6937146499443054\n",
      "Accuracy: 0.72 with Correct: 145 and Total: 200\n",
      "Epoch: 3\n",
      "Epoch Loss: 0.692345528793335\n",
      "Accuracy: 0.73 with Correct: 147 and Total: 200\n",
      "Epoch: 4\n",
      "Epoch Loss: 0.6916961362838745\n",
      "Accuracy: 0.81 with Correct: 162 and Total: 200\n",
      "----------^^^^\n",
      "Finished Training!\n",
      "Saving model state dictionary to path attack_models/attack_resnet_tinyimage.pth!\n"
     ]
    }
   ],
   "source": [
    "attack_model = MiddleAttackNN()\n",
    "attack_model.to(DEVICE)\n",
    "# Further training Parameters \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(attack_model.parameters(), lr=LEARNING_R)\n",
    "# Do everything in one function\n",
    "# Train/ Load Attack model; For every epoch show epoch loss and evaluate\n",
    "train_or_load_and_eval_atck_model(attack_model, attack_train_loader, attack_eval_post_loader, optimizer, criterion, EPOCHS, ATTACK_MODEL_PATH, DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 with Correct: 162 and Total: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_attack_model(attack_model, attack_eval_post_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
