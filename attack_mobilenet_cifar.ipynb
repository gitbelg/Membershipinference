{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import mobilenet_v2\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper_functions import train_or_load_and_eval_atck_model, create_eval_post_loader, create_shadow_post_train_loader, evaluate_attack_model, DatasetClassN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameter\n",
    "model = \"mobilenetv2\"\n",
    "model_short = \"mobilenet\"\n",
    "MODEL_MODULE = mobilenet_v2\n",
    "# Dataset parameter\n",
    "dataset = \"cifar10\"\n",
    "dataset_short = \"cifar\"\n",
    "DATASET_ENUM = DatasetClassN.Cifar\n",
    "\n",
    "## Attack model training parameters\n",
    "LEARNING_R = 0.01\n",
    "EPOCHS = 5\n",
    "MULTI_WORKERS_N = 4\n",
    "STANDARDIZE = True\n",
    "\n",
    "## Datasets\n",
    "SHADOW_DATA_PATH = f\"pickle/{dataset}/{model}/shadow.p\"\n",
    "EVALUATE_DATA_PATH = f\"pickle/{dataset}/{model}/eval.p\"\n",
    "# Save Dset create for attack model training\n",
    "ATT_TRAIN_DATA_PATH = f\"pickle/{dataset}/{model}/attack_train.p\"\n",
    "## Models\n",
    "SHADOW_MODEL_PATH = f\"shadow_models/{model}_shadow_{dataset_short}_overtrained.pth\"\n",
    "TARGET_MODEL_PATH = f\"models/{model}_{dataset}.pth\"\n",
    "ATTACK_MODEL_PATH = f\"attack_models/attack_{model_short}_{dataset_short}.pth\"\n",
    "\n",
    "DEVICE=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shadow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the shadow model trained in the other python script\n",
    "shadow_model = MODEL_MODULE(weights=None,num_classes=DATASET_ENUM.value).to(DEVICE) #resnet_target is the shadow model\n",
    "shadow_model.load_state_dict(torch.load(SHADOW_MODEL_PATH, map_location=DEVICE))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shadow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SHADOW_DATA_PATH, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "shadow_memb_data, shadow_non_memb_data = train_test_split(dataset, test_size=(1-0.5),shuffle=False)\n",
    "  \n",
    "shadow_membloader = DataLoader(shadow_memb_data, batch_size=1, shuffle=False, num_workers=1)\n",
    "shadow_non_membloader =  DataLoader(shadow_non_memb_data, batch_size=1, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Attack model training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON Members\n",
      "------SAMPLE WINDOW---------------------------------------------------------\n",
      "Number Samples: 15000\n",
      "Batchsize: 1\n",
      "Inputs:tensor([[[[0.6275, 0.6431, 0.5922,  ..., 0.6471, 0.6392, 0.6510], [0.6588, 0.6784, 0.6275,  ..., 0.6980, 0.6667, 0.6784], [0.6667, 0.6863, 0.6706,  ..., 0.7020, 0.6667, 0.6745], ..., [0.3137, 0.2941, 0.2902,  ..., 0.5216, 0.4471, 0.5686], [0.3529, 0.3137, 0.2471,  ..., 0.4863, 0.5961, 0.7451], [0.3529, 0.3137, 0.2275,  ..., 0.5529, 0.7725, 0.7686]],[[0.5294, 0.5412, 0.4784,  ..., 0.5569, 0.5490, 0.5529], [0.5569, 0.5686, 0.5098,  ..., 0.6196, 0.5843, 0.5961], [0.5529, 0.5686, 0.5451,  ..., 0.6235, 0.5922, 0.5961], ..., [0.2314, 0.2235, 0.2235,  ..., 0.3922, 0.3333, 0.4549], [0.2510, 0.2275, 0.1725,  ..., 0.3529, 0.4824, 0.6314], [0.2431, 0.2196, 0.1529,  ..., 0.4314, 0.6706, 0.6627]],[[0.4039, 0.4078, 0.3412,  ..., 0.3137, 0.3137, 0.3412], [0.4314, 0.4353, 0.3686,  ..., 0.3647, 0.3294, 0.3412], [0.4314, 0.4392, 0.4078,  ..., 0.3725, 0.3333, 0.3333], ..., [0.1255, 0.1216, 0.1294,  ..., 0.2510, 0.1765, 0.2510], [0.1529, 0.1451, 0.1020,  ..., 0.2235, 0.3255, 0.4157], [0.1529, 0.1373, 0.1020,  ..., 0.2902, 0.4941, 0.4392]]]])\n",
      "Labels:tensor([6])\n",
      "Outputs:tensor([[ 0.4937, -0.5939,0.3097, -0.3988, -0.3660, -0.1572,0.6854, -0.3678,0.1605, -0.4585]])\n",
      "One hot:tensor([[0.6854, 0.4937, 0.3097, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000]])\n",
      "Top Sigmoids: tensor([[0.6854, 0.4937, 0.3097]])\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "attack_train_loader = create_shadow_post_train_loader(shadow_non_membloader, shadow_membloader, shadow_model, batch_size=64, \\\n",
    "    multi_n= MULTI_WORKERS_N, data_class = DATASET_ENUM, device=DEVICE, save_path=ATT_TRAIN_DATA_PATH, standardize=STANDARDIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.3991,  0.2773,  0.2371,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3922,  0.2946,  0.1755,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4578,  0.1725,  0.1703,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.1503,  0.1348,  0.0235,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4818,  0.4373,  0.1972,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.8340,  0.4606,  0.4531,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6342,  0.5083,  0.2848,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6586,  0.5266,  0.3580,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.7082,  0.5151,  0.4492,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.5045,  0.4570,  0.2041,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.5640,  0.5083,  0.2679,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5345,  0.3009,  0.2384,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4167,  0.4027,  0.1427,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5073,  0.3571,  0.2954,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.2279,  0.1936,  0.1447,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3768,  0.2915,  0.0396,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.3639,  0.0889,  0.0853,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.2972,  0.1999,  0.1532,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2548,  0.2317,  0.1649,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5648,  0.4032,  0.1879,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 0.7188,  0.2821,  0.1769,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.3310,  0.2561,  0.2340,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5343,  0.2408,  0.2389,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.4447,  0.3200,  0.1953,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6786,  0.4250,  0.1221,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 0.8993,  0.4042,  0.1987,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 2.0268,  1.1353,  1.0597,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2481,  0.2407,  0.1077,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3129,  0.2248,  0.2019,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3405,  0.2281,  0.2020,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4789,  0.2329,  0.1832,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4779,  0.3337,  0.3108,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.3248,  0.1524,  0.1455,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.5992,  0.5864,  0.5445,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3041,  0.1670, -0.0099,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.9192,  0.5073,  0.2438,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3719,  0.3215,  0.3103,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2551,  0.1130,  0.1070,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.4333,  0.3003,  0.2728,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3445,  0.2762,  0.1268,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.1123,  0.0275,  0.0212,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5098,  0.3676,  0.1389,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.8039,  0.6394,  0.4374,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3262,  0.2837,  0.2173,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3147,  0.2745,  0.1614,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5031,  0.3104,  0.0920,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 1.9192,  0.4188,  0.2215,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 0.4322,  0.1247,  0.1075,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2834,  0.2313,  0.2023,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 1.4615,  1.2742,  0.4990,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.7153,  0.4269,  0.3838,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3498,  0.2126,  0.1969,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2884,  0.2571,  0.2482,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.3272,  0.2705,  0.1669,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.6572,  0.5628,  0.5250,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5053,  0.4652,  0.4484,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2580,  0.2105,  0.1830,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4884,  0.4373,  0.3268,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.3504,  0.3359,  0.2032,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4167,  0.4123,  0.1941,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.2261,  0.1931,  0.1650,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.9340,  0.3288,  0.3066,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 0.3476,  0.1873,  0.1796,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.9973,  0.7856,  0.5924,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]]]), tensor([0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,  0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,  1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "attack_sample_iter = iter(attack_train_loader)\n",
    "print (str(next(attack_sample_iter)).replace('\\n',\"\").replace(\"   \",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallAttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallAttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.sigmoid(self.fc2(self.fc1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle Size Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleAttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiddleAttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)\n",
    "        self.fc5 = nn.Linear(16, 8)\n",
    "        self.bn5 = nn.BatchNorm1d(8)\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(torch.relu(self.bn5(self.fc5(x))))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target model\n",
    "target_model = MODEL_MODULE(weights=None,num_classes=DATASET_ENUM.value)\n",
    "target_model.load_state_dict (torch.load (TARGET_MODEL_PATH, map_location=DEVICE)[\"net\"])\n",
    "target_model.eval()\n",
    "target_model.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load **Evaluation Dataset** & get Posteriors/ Member Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------SAMPLE WINDOW---------------------------------------------------------\n",
      "Number Samples: 200\n",
      "Batchsize: 1\n",
      "Inputs:tensor([[[[0.8941, 0.9216, 0.9294,  ..., 0.1765, 0.4000, 0.7059], [0.9451, 0.9569, 0.9765,  ..., 0.1882, 0.6667, 0.6157], [0.8941, 0.9569, 0.9843,  ..., 0.1373, 0.3961, 0.3961], ..., [0.2784, 0.2510, 0.2392,  ..., 0.3412, 0.3137, 0.2941], [0.3961, 0.3333, 0.2392,  ..., 0.3137, 0.2980, 0.2745], [0.4275, 0.3647, 0.2353,  ..., 0.3137, 0.3020, 0.3020]],[[0.9882, 0.9843, 0.9882,  ..., 0.2667, 0.5176, 0.8078], [1.0000, 0.9961, 1.0000,  ..., 0.2667, 0.7647, 0.7059], [0.9216, 0.9804, 0.9922,  ..., 0.1961, 0.5020, 0.5216], ..., [0.3059, 0.3137, 0.3216,  ..., 0.4078, 0.3725, 0.3176], [0.4118, 0.3882, 0.3098,  ..., 0.4039, 0.3686, 0.3176], [0.4471, 0.3882, 0.2745,  ..., 0.3608, 0.3451, 0.3451]],[[0.9882, 0.9843, 0.9882,  ..., 0.3137, 0.6392, 0.8196], [1.0000, 0.9961, 1.0000,  ..., 0.2863, 0.7843, 0.6549], [0.9294, 0.9843, 0.9922,  ..., 0.2353, 0.5137, 0.4863], ..., [0.2353, 0.2510, 0.2667,  ..., 0.2824, 0.2392, 0.1765], [0.3137, 0.3098, 0.2588,  ..., 0.2627, 0.2157, 0.1686], [0.3176, 0.2902, 0.2118,  ..., 0.2392, 0.2039, 0.1882]]]])\n",
      "Labels:tensor([1])\n",
      "Outputs:tensor([[-3.3939, -1.8873, -0.3336,0.5173, -0.3885, 10.2372, -0.8526, -0.3083, -1.6205, -1.9665]])\n",
      "One hot:tensor([[10.2372,  0.5173, -0.3083,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "Top Sigmoids: tensor([[10.2372,  0.5173, -0.3083]])\n",
      "---------------------------------------------------------------------------\n",
      "No Standarization\n"
     ]
    }
   ],
   "source": [
    "with open(EVALUATE_DATA_PATH, \"rb\") as eval_f:\n",
    "    eval_dataset = pickle.load(eval_f)\n",
    "    # Create Posteriors with target model; MULTI_WORKERS_N defines workers num of returned DL\n",
    "    attack_eval_post_loader = create_eval_post_loader (target_model, eval_dataset, MULTI_WORKERS_N, DATASET_ENUM, DEVICE, test_dataset=False, standardize=STANDARDIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attack Evaluation DL Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 1.0237e+01,  5.1730e-01, -3.0826e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.4312e+00,  5.0981e-01, -2.7521e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.1062e+01,  6.9038e-01, -4.8954e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.8281e+00,  7.7090e-01,  1.4212e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.5954e+00,  8.7125e-01,  2.9888e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.4472e+00,  1.1986e-01,  1.0038e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0364e+01, -6.1305e-02, -1.0229e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.5466e+00,  4.6691e-01, -1.5146e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0357e+01,  6.2545e-01, -3.0423e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.2281e+00, -1.7976e-01, -4.3510e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.9767e+00,  6.5998e-02, -1.9517e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 7.6929e+00,  4.7246e-01,  3.0626e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.2761e+00,  5.8081e-01, -5.9289e-02,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.9620e+00, -1.0565e-01, -3.5072e-01,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0706e+01,  2.9947e-01, -7.3508e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.6948e+00,  1.1925e+00,  4.0340e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0445e+01,  3.0757e-01, -3.0828e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]],  [[ 7.6198e+00,  5.4609e-01,  2.5896e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 7.7251e+00,  6.8454e-01,  2.0550e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]],  [[ 9.8122e+00,  9.1789e-01, -3.0138e-01,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 7.3903e+00,  3.4802e-01,  1.9171e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.6537e+00,  3.9655e-01,  3.0256e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.6094e+00,  2.4599e-01, -2.5933e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.5490e+00,  1.7551e-01, -2.8590e-01,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0538e+01,  1.1284e+00, -3.0288e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.2323e+00,  2.5745e-01, -2.5416e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],  [[ 7.0104e+00,  5.1642e-01,  3.1952e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]],  [[ 8.8384e+00,  3.7434e-01,  2.9510e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 6.2097e+00,  5.6998e-01,  5.9163e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]],  [[ 1.0197e+01,  1.1111e-01, -3.6774e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],  [[ 8.0826e+00,  5.6386e-02, -2.7759e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.0469e+00,  1.3265e+00, -4.2539e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],  [[ 8.2860e+00,  9.5048e-01, -1.1298e-01,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0160e+01,  3.7496e-01, -3.3656e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.6632e+00, -9.4072e-02, -2.5708e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.7299e+00,  6.0760e-01,  1.8948e-02,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.3359e+00,  1.1034e-01,  4.6600e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.6449e+00,  4.5184e-01, -1.3383e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.4007e+00,  7.9678e-02, -3.6592e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],  [[ 8.4610e+00,  5.3790e-01, -2.2959e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0408e+01,  7.2781e-01, -4.8610e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]],  [[ 8.6822e+00,  3.7950e-01, -2.4794e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]],  [[ 8.0577e+00,  5.2680e-01, -3.4422e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.5229e+00,  1.1477e+00, -4.2354e-02,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 6.7357e+00,  5.5900e-01, -1.7418e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.9446e+00,  8.9083e-01, -2.9506e-01,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.2417e+00,  2.2073e-01, -2.5840e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.2392e+00,  3.6708e-01,  1.3264e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.6733e+00,  8.6688e-01, -1.9812e-01,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 8.2423e+00,  5.7898e-01, -5.1564e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.4857e+00, -7.0252e-02, -3.7532e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.5803e+00,  3.0681e-01, -1.8567e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]],  [[ 1.0468e+01,  9.4252e-02, -1.0728e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]],  [[ 1.0449e+01,  2.0561e-01,  4.9160e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.3411e+00,  2.8363e-01, -1.7779e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],  [[ 8.6854e+00, -2.6087e-02, -2.7871e-01,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.2015e+00,  9.7296e-02, -2.7068e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0141e+01,  2.5980e-01,  6.3829e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.1763e+01,  3.6224e-01,  1.2696e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0341e+01,  9.3333e-02, -2.1032e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],  [[ 1.0816e+01,  2.7029e-01, -4.0606e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.0259e+01,  5.6380e-02, -4.3392e-02,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 1.1029e+01,  5.3346e-01, -2.7101e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  [[ 9.6273e+00,  2.0940e-01, -1.8195e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "eval_sample_iter = iter(attack_eval_post_loader)\n",
    "print (str(next(eval_sample_iter)).replace('\\n',\"\").replace(\"   \",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "------SAMPLE WINDOW---------------------------------------------------------\n",
      "Number Samples: 30000\n",
      "Batchsize: 64\n",
      "Inputs:tensor([[[ 1.1481,  0.6520,  0.6330,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.1025,  0.0685,  0.0503,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5624,  0.2918,  0.1066,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3418,  0.2416,  0.2339,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6157,  0.3119,  0.1775,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3105,  0.2277,  0.2219,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6464,  0.2648,  0.1184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 0.5389,  0.4622,  0.4111,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.1997,  0.1275,  0.0519,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6913,  0.4911, -0.0710,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2320,  0.2243,  0.0677,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4498,  0.3888,  0.3850,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4265,  0.3390,  0.3227,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4027,  0.3748,  0.3537,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5439,  0.4853,  0.4825,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2918,  0.2648,  0.1819,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.7285,  0.4047,  0.3925,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2731,  0.1984,  0.1699,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.1984,  0.1462,  0.1246,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3860,  0.2333,  0.0571,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.2745,  0.0319,  0.0217,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5473,  0.2955,  0.1624,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.2262,  0.1566,  0.0690,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 1.1683,  0.8415,  0.7505,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 0.4925,  0.3778,  0.1734,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3004,  0.2169, -0.0267,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3223,  0.2885,  0.2596,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5918,  0.5635,  0.1950,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5271,  0.4235,  0.0974,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5021,  0.3083,  0.2524,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 0.2816,  0.2257,  0.2027,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5713,  0.3552,  0.1727,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.8882,  0.6186,  0.4587,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4317,  0.2144,  0.2141,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3227,  0.1706,  0.1363,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4423,  0.3216,  0.2243,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6163,  0.4722,  0.2947,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3572,  0.3226,  0.2565,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3656,  0.1266,  0.1204,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 0.7890,  0.2569,  0.2514,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4378,  0.1922,  0.1205,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.2858,  0.1788,  0.1323,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5343,  0.3818,  0.2419,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.4349,  0.3151,  0.3110,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 1.0135,  0.7004,  0.2172,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],  [[ 0.3658,  0.1552,  0.1427,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.7453,  0.7101,  0.5257,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6721,  0.4122,  0.3172,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.1806,  0.1669,  0.0954,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3144,  0.1965,  0.1942,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]],  [[ 2.4109,  1.1426,  0.6211,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3786,  0.1144,  0.0773,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6431,  0.5577,  0.5080,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4983,  0.2017,  0.1699,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.7186,  0.6842,  0.2985,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000]],  [[ 0.2326,  0.1709,  0.1366,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5685,  0.2661,  0.2425,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4450,  0.2707,  0.1927,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.6112,  0.3748,  0.3430,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4741,  0.2934,  0.0648,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.3772,  0.3068,  0.2085,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4763,  0.4584,  0.4469,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.4500,  0.3604,  0.2728,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000]],  [[ 0.5052,  0.4090,  0.3383,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000]]])\n",
      "Squeezed Input: tensor([[ 1.1481,  0.6520,  0.6330,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1025,  0.0685,  0.0503,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5624,  0.2918,  0.1066,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3418,  0.2416,  0.2339,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6157,  0.3119,  0.1775,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3105,  0.2277,  0.2219,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6464,  0.2648,  0.1184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.5389,  0.4622,  0.4111,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1997,  0.1275,  0.0519,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6913,  0.4911, -0.0710,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2320,  0.2243,  0.0677,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4498,  0.3888,  0.3850,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4265,  0.3390,  0.3227,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4027,  0.3748,  0.3537,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5439,  0.4853,  0.4825,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2918,  0.2648,  0.1819,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7285,  0.4047,  0.3925,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2731,  0.1984,  0.1699,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1984,  0.1462,  0.1246,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3860,  0.2333,  0.0571,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.2745,  0.0319,  0.0217,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5473,  0.2955,  0.1624,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.2262,  0.1566,  0.0690,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.1683,  0.8415,  0.7505,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.4925,  0.3778,  0.1734,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3004,  0.2169, -0.0267,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3223,  0.2885,  0.2596,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5918,  0.5635,  0.1950,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5271,  0.4235,  0.0974,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5021,  0.3083,  0.2524,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.2816,  0.2257,  0.2027,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5713,  0.3552,  0.1727,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.8882,  0.6186,  0.4587,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4317,  0.2144,  0.2141,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3227,  0.1706,  0.1363,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4423,  0.3216,  0.2243,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6163,  0.4722,  0.2947,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3572,  0.3226,  0.2565,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3656,  0.1266,  0.1204,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.7890,  0.2569,  0.2514,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4378,  0.1922,  0.1205,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2858,  0.1788,  0.1323,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5343,  0.3818,  0.2419,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.4349,  0.3151,  0.3110,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0135,  0.7004,  0.2172,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.3658,  0.1552,  0.1427,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7453,  0.7101,  0.5257,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6721,  0.4122,  0.3172,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.1806,  0.1669,  0.0954,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3144,  0.1965,  0.1942,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [ 2.4109,  1.1426,  0.6211,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3786,  0.1144,  0.0773,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6431,  0.5577,  0.5080,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4983,  0.2017,  0.1699,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.7186,  0.6842,  0.2985,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.2326,  0.1709,  0.1366,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5685,  0.2661,  0.2425,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4450,  0.2707,  0.1927,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.6112,  0.3748,  0.3430,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4741,  0.2934,  0.0648,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3772,  0.3068,  0.2085,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4763,  0.4584,  0.4469,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4500,  0.3604,  0.2728,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5052,  0.4090,  0.3383,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000]])\n",
      "Labels:tensor([[0.],[0.],[0.],[1.],[0.],[1.],[1.],[0.],[0.],[0.],[0.],[1.],[1.],[1.],[1.],[0.],[1.],[0.],[0.],[0.],[0.],[0.],[1.],[1.],[0.],[0.],[1.],[0.],[1.],[1.],[0.],[0.],[1.],[1.],[0.],[1.],[0.],[1.],[0.],[0.],[0.],[1.],[0.],[1.],[0.],[0.],[1.],[1.],[1.],[0.],[1.],[0.],[0.],[1.],[1.],[1.],[1.],[1.],[1.],[1.],[1.],[0.],[1.],[0.]])\n",
      "Outputs:tensor([[0.6337],[0.4967],[0.5250],[0.4992],[0.6206],[0.5598],[0.6108],[0.4858],[0.4967],[0.7343],[0.6862],[0.7472],[0.5119],[0.5488],[0.7388],[0.5924],[0.4439],[0.4715],[0.4967],[0.4977],[0.5062],[0.5458],[0.6104],[0.4888],[0.6156],[0.4185],[0.7246],[0.6909],[0.5352],[0.3208],[0.5745],[0.5138],[0.5706],[0.4792],[0.4486],[0.5231],[0.5032],[0.7360],[0.6773],[0.7823],[0.4967],[0.5029],[0.5672],[0.7389],[0.6773],[0.5917],[0.4967],[0.5042],[0.5274],[0.4084],[0.5243],[0.6376],[0.6493],[0.4973],[0.6212],[0.5152],[0.4972],[0.6671],[0.6276],[0.6606],[0.6231],[0.4378],[0.5858],[0.3854]], grad_fn=<SigmoidBackward0>)\n",
      "Loss:0.7113059163093567\n",
      "---------------------------------------------------------------------------\n",
      "Epoch Loss: 0.6989153232892354\n",
      "Accuracy: 0.49 with Correct: 98 and Total: 200\n",
      "Epoch: 2\n",
      "Epoch Loss: 0.6939081569671631\n",
      "Accuracy: 0.43 with Correct: 87 and Total: 200\n",
      "Epoch: 3\n",
      "Epoch Loss: 0.693629505888621\n",
      "Accuracy: 0.50 with Correct: 100 and Total: 200\n",
      "Epoch: 4\n",
      "Epoch Loss: 0.6932887381235758\n",
      "Accuracy: 0.48 with Correct: 96 and Total: 200\n",
      "Epoch: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(attack_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_R)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Do everything in one function\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train/ Load Attack model; For every epoch show epoch loss and evaluate\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrain_or_load_and_eval_atck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattack_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_eval_post_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK_MODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Studium\\Master\\Semester 2\\Attacks on ML\\project\\AAML\\helper_functions.py:100\u001b[0m, in \u001b[0;36mtrain_or_load_and_eval_atck_model\u001b[1;34m(model, train_loader, eval_loader, optimizer, criterion, epochs, save_path, device)\u001b[0m\n\u001b[0;32m     98\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     99\u001b[0m sample_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39msampler)\n\u001b[1;32m--> 100\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensures input tensors are floats\u001b[39;49;00m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensures labels are floats and reshaped correctly\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User-1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py:410\u001b[0m, in \u001b[0;36mreduce_storage\u001b[1;34m(storage)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce_storage\u001b[39m(storage):\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_sharing_strategy\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    414\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pickle CUDA storage; try pickling a CUDA tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    415\u001b[0m         )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1207\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attack_model = MiddleAttackNN()\n",
    "attack_model.to(DEVICE)\n",
    "# Further training Parameters \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(attack_model.parameters(), lr=LEARNING_R)\n",
    "# Do everything in one function\n",
    "# Train/ Load Attack model; For every epoch show epoch loss and evaluate\n",
    "train_or_load_and_eval_atck_model(attack_model, attack_train_loader, attack_eval_post_loader, optimizer, criterion, EPOCHS, ATTACK_MODEL_PATH, DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.475"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_attack_model(attack_model, attack_eval_post_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
