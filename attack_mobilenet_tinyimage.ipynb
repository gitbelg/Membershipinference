{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import mobilenet_v2\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper_functions import train_or_load_and_eval_atck_model, create_eval_post_loader, create_shadow_post_train_loader, evaluate_attack_model, DatasetClassN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameter\n",
    "model = \"mobilenetv2\"\n",
    "model_short = \"mobilenet\"\n",
    "MODEL_MODULE = mobilenet_v2\n",
    "# Dataset parameter\n",
    "dataset = \"tinyimagenet\"\n",
    "dataset_short = \"tinyimage\"\n",
    "DATASET_ENUM = DatasetClassN.Tinyimage\n",
    "\n",
    "## Attack model training parameters\n",
    "LEARNING_R = 0.001\n",
    "EPOCHS = 3\n",
    "MULTI_WORKERS_N = 1\n",
    "\n",
    "## Datasets\n",
    "SHADOW_DATA_PATH = f\"pickle/{dataset}/{model}/shadow.p\"\n",
    "EVALUATE_DATA_PATH = f\"pickle/{dataset}/{model}/eval.p\"\n",
    "# Save Dset create for attack model training\n",
    "ATT_TRAIN_DATA_PATH = f\"pickle/{dataset}/{model}/attack_train.p\"\n",
    "## Models\n",
    "SHADOW_MODEL_PATH = f\"shadow_models/{model}_shadow_{dataset_short}_overtrained.pth\"\n",
    "TARGET_MODEL_PATH = f\"models/{model}_{dataset}.pth\"\n",
    "ATTACK_MODEL_PATH = f\"attack_models/attack_{model_short}_{dataset_short}.pth\"\n",
    "\n",
    "DEVICE=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shadow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the shadow model trained in the other python script\n",
    "shadow_model = MODEL_MODULE(weights=None,num_classes=DATASET_ENUM.value).to(DEVICE) #resnet_target is the shadow model\n",
    "shadow_model.load_state_dict(torch.load(SHADOW_MODEL_PATH, map_location=DEVICE))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shadow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SHADOW_DATA_PATH, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "shadow_memb_data, shadow_non_memb_data = train_test_split(dataset, test_size=(1-0.5),shuffle=False)\n",
    "  \n",
    "shadow_membloader = DataLoader(shadow_memb_data, batch_size=1, shuffle=False, num_workers=1)\n",
    "shadow_non_membloader =  DataLoader(shadow_non_memb_data, batch_size=1, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Attack model training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack dataset was already established previosly, loading dataset from \"pickle/tinyimagenet/mobilenetv2/attack_train.p\".\n"
     ]
    }
   ],
   "source": [
    "attack_train_loader = create_shadow_post_train_loader(shadow_non_membloader, shadow_membloader, shadow_model, batch_size=64, \\\n",
    "    multi_n= MULTI_WORKERS_N, device=DEVICE, save_path=ATT_TRAIN_DATA_PATH, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 1.7030,  0.6128,  0.5038]],  [[ 2.3362,  2.3186,  2.0089]],  [[ 3.3956,  3.2006,  2.8834]],  [[ 2.1359,  0.7500,  0.7089]],  [[ 2.7621,  2.3960,  2.3026]],  [[ 2.2115,  0.7964,  0.0623]],  [[ 2.6597,  2.1870,  1.3616]],  [[ 1.3809,  1.0832,  1.0585]],  [[ 4.5301,  1.8755,  1.6888]],  [[ 1.0893,  0.6552,  0.0521]],  [[ 1.1781,  0.9118,  0.8309]],  [[ 2.6503,  1.7803,  1.2421]],  [[ 2.8521,  1.2624,  1.1395]],  [[ 1.3660,  0.9558,  0.6079]],  [[ 1.1571,  0.7434,  0.5456]],  [[ 1.3294,  0.2896,  0.2694]],  [[ 3.7332,  1.8675,  1.8548]],  [[ 1.6870,  0.9661,  0.8747]],  [[ 0.9435,  0.8471,  0.5223]],  [[ 0.7366,  0.5973,  0.4091]],  [[ 3.2018,  2.9480,  2.2033]],  [[ 1.8640,  1.1861,  1.0658]],  [[ 2.4932,  1.9381,  1.5768]],  [[ 0.6242,  0.3315,  0.2648]],  [[ 1.8231,  1.7536,  1.7149]],  [[ 1.5350,  1.4737,  1.3058]],  [[ 3.3500,  3.1747,  2.9893]],  [[ 1.7409,  1.4165,  1.2084]],  [[ 2.2179,  1.8106,  1.8041]],  [[ 1.6116,  1.5550,  1.1991]],  [[ 1.2388,  1.1559,  0.8741]],  [[ 2.9771,  2.1810,  1.7306]],  [[ 2.4373,  2.0151,  1.9197]],  [[ 2.1597,  1.0355,  0.9967]],  [[ 1.6021,  0.9110,  0.7864]],  [[ 2.8594,  1.9433,  1.7912]],  [[ 1.2339,  0.8216,  0.3165]],  [[ 8.8929,  8.3488,  7.5512]],  [[ 1.1111,  0.7960,  0.7871]],  [[ 5.9057,  4.6578,  3.1126]],  [[ 2.2330,  1.9565,  1.8463]],  [[ 1.8784,  1.8085,  1.7495]],  [[ 3.7305,  3.3084,  2.6757]],  [[ 1.1535,  0.5468,  0.3409]],  [[ 1.6788,  1.4143, -0.1529]],  [[ 1.7111,  1.0994,  0.9534]],  [[ 2.5442,  1.8424,  1.5201]],  [[ 1.0206,  0.5402, -0.0911]],  [[ 3.4225,  2.9163,  2.5050]],  [[ 0.9689,  0.8380,  0.5565]],  [[ 1.6751,  1.1982,  1.0061]],  [[ 0.1228,  0.0238,  0.0138]],  [[ 3.4954,  2.0196,  1.6169]],  [[ 0.4729,  0.4447,  0.2690]],  [[ 2.2296,  1.3518,  1.1021]],  [[ 1.4299,  0.9295,  0.8052]],  [[ 2.3754,  2.3459,  2.3382]],  [[ 1.0390,  0.3253,  0.3163]],  [[ 2.3921,  2.3498,  1.7517]],  [[ 2.7718,  2.3749,  2.3101]],  [[ 0.1598,  0.0094, -0.2150]],  [[ 1.8558,  1.4795,  0.8090]],  [[ 1.6510,  1.2726,  0.7989]],  [[ 0.5859,  0.4490,  0.4417]]]), tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,  0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,  1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "attack_sample_iter = iter(attack_train_loader)\n",
    "print (str(next(attack_sample_iter)).replace('\\n',\"\").replace(\"   \",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallAttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallAttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.sigmoid(self.fc2(self.fc1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle Size Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleAttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiddleAttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)\n",
    "        self.fc5 = nn.Linear(16, 8)\n",
    "        self.bn5 = nn.BatchNorm1d(8)\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(torch.relu(self.bn5(self.fc5(x))))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target model\n",
    "target_model = MODEL_MODULE(weights=None,num_classes=DATASET_ENUM.value)\n",
    "target_model.load_state_dict (torch.load (TARGET_MODEL_PATH, map_location=DEVICE)[\"net\"])\n",
    "target_model.eval()\n",
    "target_model.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load **Evaluation Dataset** & get Posteriors/ Member Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------SAMPLE WINDOW---------------------------------------------------------\n",
      "Number Samples: 200\n",
      "Batchsize: 1\n",
      "Inputs:tensor([[[[0.9686, 0.9686, 0.9725,  ..., 0.9765, 0.9725, 0.9686], [0.9608, 0.9647, 0.9647,  ..., 0.9725, 0.9686, 0.9686], [0.9647, 0.9647, 0.9686,  ..., 0.9686, 0.9647, 0.9647], ..., [0.3843, 0.1294, 0.3294,  ..., 0.6627, 0.6980, 0.4980], [0.1333, 0.3804, 0.4118,  ..., 0.4078, 0.5020, 0.2902], [0.1569, 0.2863, 0.4353,  ..., 0.4510, 0.6549, 0.4078]],[[0.9765, 0.9765, 0.9804,  ..., 0.9843, 0.9804, 0.9765], [0.9686, 0.9725, 0.9725,  ..., 0.9804, 0.9765, 0.9765], [0.9725, 0.9725, 0.9765,  ..., 0.9765, 0.9725, 0.9725], ..., [0.3647, 0.1137, 0.3176,  ..., 0.5765, 0.6118, 0.4118], [0.1098, 0.3608, 0.4000,  ..., 0.3098, 0.4039, 0.1922], [0.1294, 0.2667, 0.4235,  ..., 0.3490, 0.5490, 0.3020]],[[0.9333, 0.9333, 0.9373,  ..., 0.9412, 0.9373, 0.9333], [0.9255, 0.9294, 0.9294,  ..., 0.9373, 0.9333, 0.9333], [0.9294, 0.9294, 0.9333,  ..., 0.9333, 0.9294, 0.9294], ..., [0.1451, 0.0000, 0.0157,  ..., 0.2392, 0.2745, 0.0745], [0.0000, 0.1412, 0.1216,  ..., 0.0471, 0.1451, 0.0000], [0.0000, 0.0510, 0.1608,  ..., 0.1255, 0.3333, 0.0863]]]], device='cuda:0')\n",
      "Labels:tensor([1])\n",
      "Outputs:tensor([[ 0.4925,0.7019,1.8541,2.6853,0.1122,0.4703,0.4657,1.5578,2.7969,0.2969, -0.0350,1.4328, -3.7095, -1.7368, -0.0616,0.6646,1.7536, -1.2033, -0.5835,1.4253,4.6648,1.0336, -2.4239,0.6449, -1.3258, -0.1582,0.6085,2.3937,2.6217, -1.2030, -4.5475, -2.1369, -1.6482,0.9976,4.9745,0.7253, -0.9326,2.6758, -3.0398,0.0841,2.0644, -0.3877,4.7155,2.6095, -0.8973, -0.2006, -2.2642, -1.8912,0.5155,5.2687,3.0943,2.8381, 13.5679,5.8385,3.2214, -1.2395,3.1005,3.3928,0.2908, -3.4924, -0.4880, -0.1672, -1.5264,0.2094,0.3934, -1.6441,4.9418, -0.1348,1.2011,3.5640, -0.4594, -2.7639,0.9806, -1.4823,0.3027,1.6067, -0.4682, -2.6888,2.3430,0.3176,0.0673,0.2947, -1.2473, -4.4172,3.8386, -0.5872, -2.3189, -1.9837, -2.2672,2.2100, -4.6268,2.6411, -1.7067, -1.1873, -1.2922,1.9940,0.1152, -1.2585,1.6353,2.5041, -1.9893,1.3272, -2.8423,3.2245, -0.7746, -2.2757, -2.0321,2.0781, -0.2510,0.8812, -0.8255,0.1134, -3.7675, -1.7079,5.4727,0.0395, -3.6180, -0.4508,3.8519,0.2185, -0.3826, -2.1689,0.9707, -1.4700, -2.2565, -1.9285, -1.5072, -3.1649, -0.5168,1.2508, -1.5264,2.1843, -1.1995, -0.6503, -1.1755, -2.4660, -1.7065, -1.0825, -4.3573,1.7748, -1.9619, -4.7868, -0.2399,3.0838, -1.7038, -0.2829,0.9655, -3.6001, -0.2558, -3.1754,0.1771, -2.9879,0.1816,1.0272,1.8759, -0.1429,0.7951, -0.8759,0.4756, -1.9061, -1.2312, -1.1019,2.9841, -2.6066,2.8457,0.8943, -1.6401, -0.1127, -0.5298, -2.3331,3.2348,4.6455, -1.6802,1.9260, -1.1920,0.6639, -0.0459, -1.5392,0.6645, -2.6598, -1.9408, -0.8512, -3.2321, -3.7985, -5.0127,1.3038, -2.0002, -1.3991, -1.4480, -3.3669, -0.1576, -1.1252,2.3770, -0.8301,4.9059,3.3771, -1.4965,2.3266,1.4266, -2.1473]], device='cuda:0')\n",
      "Top Sigmoids: tensor([[13.5679,  5.8385,  5.4727]])\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open(EVALUATE_DATA_PATH, \"rb\") as eval_f:\n",
    "    eval_dataset = pickle.load(eval_f)\n",
    "    # Create Posteriors with target model; MULTI_WORKERS_N defines workers num of returned DL\n",
    "    attack_eval_post_loader = create_eval_post_loader (target_model, eval_dataset, MULTI_WORKERS_N, DEVICE, test_dataset=False, standardize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attack Evaluation DL Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[13.5679,  5.8385,  5.4727]],  [[11.7774,  5.1659,  4.6183]],  [[13.3103,  8.1171,  7.0456]],  [[13.3904,  7.4329,  6.8716]],  [[11.7441,  6.6519,  5.4875]],  [[14.0014,  7.6744,  7.2380]],  [[12.9404,  5.9869,  5.9537]],  [[13.9780,  6.2884,  6.0444]],  [[13.6892,  7.4124,  6.7361]],  [[12.5785,  7.3046,  6.2111]],  [[14.1772,  8.3490,  7.9208]],  [[11.6784,  5.1415,  4.5934]],  [[12.9706,  6.0249,  5.8534]],  [[15.1840,  8.7963,  7.2625]],  [[13.2971,  6.5384,  6.2782]],  [[13.0019,  6.3516,  6.1218]],  [[13.3297,  6.4383,  5.7660]],  [[11.9722,  5.6946,  4.8598]],  [[13.7635,  7.2811,  7.0462]],  [[12.5942,  7.0454,  5.9499]],  [[12.5188,  6.4181,  5.3020]],  [[12.9748,  6.8068,  6.4039]],  [[11.4711,  4.9788,  4.5095]],  [[11.8016,  5.3340,  4.8724]],  [[12.6197,  5.8138,  5.2405]],  [[12.1706,  5.5856,  5.2790]],  [[13.2897,  7.3200,  6.3253]],  [[13.3285,  7.5621,  5.6963]],  [[14.6852,  7.2786,  7.0723]],  [[12.4365,  4.8604,  4.7229]],  [[13.4672,  6.5357,  6.2461]],  [[14.6180,  8.7964,  7.3700]],  [[11.4834,  4.9874,  4.9066]],  [[13.3830,  7.3448,  6.3146]],  [[12.4397,  4.6194,  4.6037]],  [[12.8483,  5.8610,  5.3571]],  [[11.9500,  4.8204,  4.7110]],  [[12.6886,  5.9565,  5.1275]],  [[12.6501,  7.3661,  5.6665]],  [[12.3651,  6.1648,  6.0060]],  [[12.6309,  6.3056,  5.7362]],  [[12.0397,  6.4780,  6.0866]],  [[12.6650,  7.0618,  6.5039]],  [[11.6541,  5.8150,  5.6486]],  [[11.9694,  5.1686,  4.4025]],  [[13.7283,  8.2426,  5.8453]],  [[11.9754,  6.0104,  5.3649]],  [[13.6048,  7.3538,  7.1774]],  [[13.3982,  7.8437,  6.4215]],  [[13.1018,  6.0029,  5.8162]],  [[12.2202,  5.6939,  5.5962]],  [[14.2720,  8.1012,  7.1952]],  [[12.3264,  6.0493,  5.1484]],  [[12.5112,  6.0073,  5.6175]],  [[12.7121,  5.6810,  5.6808]],  [[14.2056,  6.5442,  5.9989]],  [[12.7252,  5.8225,  5.2000]],  [[12.5572,  6.4063,  5.8884]],  [[13.3255,  5.3653,  5.2758]],  [[13.3088,  6.5335,  6.2472]],  [[13.7251,  7.8472,  7.0869]],  [[12.4890,  5.2186,  4.7256]],  [[11.7699,  5.4873,  4.8063]],  [[12.0888,  5.8504,  5.0555]]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "eval_sample_iter = iter(attack_eval_post_loader)\n",
    "print (str(next(eval_sample_iter)).replace('\\n',\"\").replace(\"   \",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "------SAMPLE WINDOW---------------------------------------------------------\n",
      "Number Samples: 50000\n",
      "Batchsize: 64\n",
      "Inputs:tensor([[[ 2.1698e+00,  1.2757e+00,  6.7375e-01]],  [[ 1.8087e+00,  1.7401e+00,  1.4687e+00]],  [[ 1.0782e+00,  1.0232e+00,  9.5794e-01]],  [[ 2.4152e+00,  1.7452e+00,  1.2688e+00]],  [[ 1.9492e+00,  1.8756e+00,  1.6512e+00]],  [[ 1.3212e+00,  7.8907e-01,  5.8626e-01]],  [[ 5.1405e-01,  1.5642e-02, -2.5709e-02]],  [[ 1.3537e+00,  1.0993e+00,  1.0211e+00]],  [[ 1.0655e+00,  8.7155e-01,  6.2335e-01]],  [[ 2.9499e+00,  1.8178e+00,  1.5377e+00]],  [[ 1.7015e+00,  1.6227e+00,  1.0361e+00]],  [[ 2.6198e+00,  2.3277e+00,  2.2493e+00]],  [[ 5.7776e+00,  5.2099e+00,  4.9542e+00]],  [[ 2.2476e+00,  2.0817e+00,  1.9666e+00]],  [[ 1.5628e+00,  1.2597e+00,  9.7013e-01]],  [[ 2.0744e+00,  1.8343e+00,  1.7495e+00]],  [[ 1.6419e+00,  1.5372e+00,  1.2912e+00]],  [[ 1.9054e+00,  1.3794e+00,  9.3877e-01]],  [[ 1.0367e+00,  6.6082e-01,  6.2882e-01]],  [[ 2.2811e-01,  4.8819e-02, -2.5078e-02]],  [[ 1.0362e+00,  7.4268e-01,  1.7226e-01]],  [[ 2.0819e+00,  1.9730e+00,  1.3382e+00]],  [[ 2.8980e+00,  2.0243e+00,  1.4906e+00]],  [[ 4.4333e+00,  3.5244e+00,  3.1463e+00]],  [[ 1.7291e+00,  8.5885e-01,  2.8768e-01]],  [[ 3.3317e+00,  3.0592e+00,  2.3648e+00]],  [[ 2.2572e+00,  1.4241e+00,  1.1522e+00]],  [[ 2.3186e+00,  1.8674e+00,  1.0841e+00]],  [[ 1.8808e+00,  1.8084e+00,  1.7115e+00]],  [[ 4.1805e+00,  3.5681e+00,  2.4290e+00]],  [[ 1.6546e+00,  3.0860e-01,  1.7094e-01]],  [[ 1.5690e+00,  7.0004e-01,  5.2371e-01]],  [[ 1.6341e+00,  1.0661e+00,  1.0203e+00]],  [[ 2.0424e+00,  1.5269e+00,  1.0889e+00]],  [[ 3.5837e+00,  3.3022e+00,  3.1508e+00]],  [[ 5.0761e-01,  3.9480e-01,  1.4701e-01]],  [[ 1.2445e+00,  8.1942e-01,  8.1912e-01]],  [[ 2.6458e+00,  1.2691e+00,  1.2226e+00]],  [[ 8.3507e-01,  3.0980e-01,  2.3592e-01]],  [[ 2.5489e+00,  2.5437e+00,  2.0734e+00]],  [[ 1.9758e+00,  1.8471e+00,  1.8468e+00]],  [[ 1.3363e+00,  9.0502e-01,  5.6652e-01]],  [[ 1.6309e+00,  1.3686e+00,  1.2490e+00]],  [[ 2.0446e+00,  1.8041e+00,  1.4093e+00]],  [[ 9.1532e-01,  9.1108e-01,  5.5124e-01]],  [[ 1.0364e+00,  7.0462e-01,  7.0323e-01]],  [[ 2.3022e+00,  1.6735e+00,  1.3051e+00]],  [[ 3.2940e+00,  2.5767e+00,  2.4395e+00]],  [[ 1.4255e+00,  7.5243e-01,  5.1914e-01]],  [[ 3.7658e+00,  2.1361e+00,  9.3067e-01]],  [[ 1.7019e+00,  8.0212e-01,  5.7533e-01]],  [[ 1.1206e+00,  1.0899e+00,  1.0452e+00]],  [[ 1.3305e+00,  1.2229e+00,  1.2014e+00]],  [[ 2.8800e+00,  2.0599e+00,  1.2820e+00]],  [[ 6.1575e+00,  3.0022e+00,  2.5339e+00]],  [[ 2.5027e+00,  1.3039e+00,  1.2880e+00]],  [[ 1.8519e+00,  1.2406e+00,  9.2349e-01]],  [[ 1.7899e+00,  1.6893e+00,  1.1385e+00]],  [[ 2.9850e+00,  6.2540e-01,  5.4473e-01]],  [[ 1.1793e+00,  1.1136e+00,  6.4381e-01]],  [[ 1.2888e+00,  2.4137e-01, -2.5484e-03]],  [[ 9.0626e+00,  6.8503e+00,  6.7944e+00]],  [[ 1.2944e+00,  1.0681e+00,  9.0609e-01]],  [[ 2.9586e+00,  1.1400e+00,  6.5083e-01]]], device='cuda:0')\n",
      "Squeezed Input: tensor([[ 2.1698e+00,  1.2757e+00,  6.7375e-01],\n",
      "        [ 1.8087e+00,  1.7401e+00,  1.4687e+00],\n",
      "        [ 1.0782e+00,  1.0232e+00,  9.5794e-01],\n",
      "        [ 2.4152e+00,  1.7452e+00,  1.2688e+00],\n",
      "        [ 1.9492e+00,  1.8756e+00,  1.6512e+00],\n",
      "        [ 1.3212e+00,  7.8907e-01,  5.8626e-01],\n",
      "        [ 5.1405e-01,  1.5642e-02, -2.5709e-02],\n",
      "        [ 1.3537e+00,  1.0993e+00,  1.0211e+00],\n",
      "        [ 1.0655e+00,  8.7155e-01,  6.2335e-01],\n",
      "        [ 2.9499e+00,  1.8178e+00,  1.5377e+00],\n",
      "        [ 1.7015e+00,  1.6227e+00,  1.0361e+00],\n",
      "        [ 2.6198e+00,  2.3277e+00,  2.2493e+00],\n",
      "        [ 5.7776e+00,  5.2099e+00,  4.9542e+00],\n",
      "        [ 2.2476e+00,  2.0817e+00,  1.9666e+00],\n",
      "        [ 1.5628e+00,  1.2597e+00,  9.7013e-01],\n",
      "        [ 2.0744e+00,  1.8343e+00,  1.7495e+00],\n",
      "        [ 1.6419e+00,  1.5372e+00,  1.2912e+00],\n",
      "        [ 1.9054e+00,  1.3794e+00,  9.3877e-01],\n",
      "        [ 1.0367e+00,  6.6082e-01,  6.2882e-01],\n",
      "        [ 2.2811e-01,  4.8819e-02, -2.5078e-02],\n",
      "        [ 1.0362e+00,  7.4268e-01,  1.7226e-01],\n",
      "        [ 2.0819e+00,  1.9730e+00,  1.3382e+00],\n",
      "        [ 2.8980e+00,  2.0243e+00,  1.4906e+00],\n",
      "        [ 4.4333e+00,  3.5244e+00,  3.1463e+00],\n",
      "        [ 1.7291e+00,  8.5885e-01,  2.8768e-01],\n",
      "        [ 3.3317e+00,  3.0592e+00,  2.3648e+00],\n",
      "        [ 2.2572e+00,  1.4241e+00,  1.1522e+00],\n",
      "        [ 2.3186e+00,  1.8674e+00,  1.0841e+00],\n",
      "        [ 1.8808e+00,  1.8084e+00,  1.7115e+00],\n",
      "        [ 4.1805e+00,  3.5681e+00,  2.4290e+00],\n",
      "        [ 1.6546e+00,  3.0860e-01,  1.7094e-01],\n",
      "        [ 1.5690e+00,  7.0004e-01,  5.2371e-01],\n",
      "        [ 1.6341e+00,  1.0661e+00,  1.0203e+00],\n",
      "        [ 2.0424e+00,  1.5269e+00,  1.0889e+00],\n",
      "        [ 3.5837e+00,  3.3022e+00,  3.1508e+00],\n",
      "        [ 5.0761e-01,  3.9480e-01,  1.4701e-01],\n",
      "        [ 1.2445e+00,  8.1942e-01,  8.1912e-01],\n",
      "        [ 2.6458e+00,  1.2691e+00,  1.2226e+00],\n",
      "        [ 8.3507e-01,  3.0980e-01,  2.3592e-01],\n",
      "        [ 2.5489e+00,  2.5437e+00,  2.0734e+00],\n",
      "        [ 1.9758e+00,  1.8471e+00,  1.8468e+00],\n",
      "        [ 1.3363e+00,  9.0502e-01,  5.6652e-01],\n",
      "        [ 1.6309e+00,  1.3686e+00,  1.2490e+00],\n",
      "        [ 2.0446e+00,  1.8041e+00,  1.4093e+00],\n",
      "        [ 9.1532e-01,  9.1108e-01,  5.5124e-01],\n",
      "        [ 1.0364e+00,  7.0462e-01,  7.0323e-01],\n",
      "        [ 2.3022e+00,  1.6735e+00,  1.3051e+00],\n",
      "        [ 3.2940e+00,  2.5767e+00,  2.4395e+00],\n",
      "        [ 1.4255e+00,  7.5243e-01,  5.1914e-01],\n",
      "        [ 3.7658e+00,  2.1361e+00,  9.3067e-01],\n",
      "        [ 1.7019e+00,  8.0212e-01,  5.7533e-01],\n",
      "        [ 1.1206e+00,  1.0899e+00,  1.0452e+00],\n",
      "        [ 1.3305e+00,  1.2229e+00,  1.2014e+00],\n",
      "        [ 2.8800e+00,  2.0599e+00,  1.2820e+00],\n",
      "        [ 6.1575e+00,  3.0022e+00,  2.5339e+00],\n",
      "        [ 2.5027e+00,  1.3039e+00,  1.2880e+00],\n",
      "        [ 1.8519e+00,  1.2406e+00,  9.2349e-01],\n",
      "        [ 1.7899e+00,  1.6893e+00,  1.1385e+00],\n",
      "        [ 2.9850e+00,  6.2540e-01,  5.4473e-01],\n",
      "        [ 1.1793e+00,  1.1136e+00,  6.4381e-01],\n",
      "        [ 1.2888e+00,  2.4137e-01, -2.5484e-03],\n",
      "        [ 9.0626e+00,  6.8503e+00,  6.7944e+00],\n",
      "        [ 1.2944e+00,  1.0681e+00,  9.0609e-01],\n",
      "        [ 2.9586e+00,  1.1400e+00,  6.5083e-01]], device='cuda:0')\n",
      "Labels:tensor([[0.],[0.],[0.],[1.],[1.],[0.],[0.],[0.],[0.],[1.],[1.],[0.],[1.],[0.],[0.],[1.],[1.],[0.],[1.],[0.],[1.],[1.],[0.],[0.],[0.],[0.],[1.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[1.],[0.],[0.],[0.],[1.],[1.],[0.],[1.],[0.],[0.],[1.],[1.],[1.],[0.],[0.],[0.],[1.],[0.],[0.],[1.],[1.],[0.],[1.],[1.],[0.],[1.],[1.],[0.],[0.]], device='cuda:0')\n",
      "Outputs:tensor([[0.5671],[0.5366],[0.5429],[0.6894],[0.5657],[0.5113],[0.5436],[0.5423],[0.5950],[0.5190],[0.5672],[0.4791],[0.6796],[0.6538],[0.5436],[0.6657],[0.7310],[0.5405],[0.6008],[0.6555],[0.5951],[0.6160],[0.5312],[0.7282],[0.5935],[0.7358],[0.5947],[0.6126],[0.7138],[0.5436],[0.5117],[0.5225],[0.6469],[0.5301],[0.4053],[0.6712],[0.6185],[0.6947],[0.4839],[0.5878],[0.5579],[0.5142],[0.6859],[0.5807],[0.8086],[0.7091],[0.6745],[0.4654],[0.5531],[0.7875],[0.6752],[0.5436],[0.5436],[0.6133],[0.6163],[0.5436],[0.5410],[0.5593],[0.7559],[0.7525],[0.5508],[0.8437],[0.5436],[0.5321]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "Loss:0.7496343851089478\n",
      "---------------------------------------------------------------------------\n",
      "Epoch Loss: 0.6993002475738526\n",
      "Accuracy: 32.96\n",
      "Epoch: 2\n",
      "Epoch Loss: 0.6930542448425293\n",
      "Accuracy: 32.00\n",
      "Epoch: 3\n",
      "Epoch Loss: 0.6928741218566895\n",
      "Accuracy: 32.92\n",
      "----------^^^^\n",
      "Finished Training!\n",
      "Saving model state dictionary to path attack_models/attack_mobilenet_tinyimage.pth!\n"
     ]
    }
   ],
   "source": [
    "attack_model = MiddleAttackNN()\n",
    "attack_model.to(DEVICE)\n",
    "# Further training Parameters \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(attack_model.parameters(), lr=LEARNING_R)\n",
    "# Do everything in one function\n",
    "# Train/ Load Attack model; For every epoch show epoch loss and evaluate\n",
    "train_or_load_and_eval_atck_model(attack_model, attack_train_loader, attack_eval_post_loader, optimizer, criterion, EPOCHS, ATTACK_MODEL_PATH, DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.92\n"
     ]
    }
   ],
   "source": [
    "evaluate_attack_model(attack_model, attack_eval_post_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
