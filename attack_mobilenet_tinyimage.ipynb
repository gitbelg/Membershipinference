{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import mobilenet_v2\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper_functions import train_or_load_and_eval_atck_model, create_eval_post_loader, create_shadow_post_train_loader, evaluate_attack_model, DatasetClassN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameter\n",
    "model = \"mobilenetv2\"\n",
    "model_short = \"mobilenet\"\n",
    "MODEL_MODULE = mobilenet_v2\n",
    "# Dataset parameter\n",
    "dataset = \"tinyimagenet\"\n",
    "dataset_short = \"tinyimage\"\n",
    "DATASET_ENUM = DatasetClassN.Tinyimage\n",
    "\n",
    "## Attack model training parameters\n",
    "LEARNING_R = 0.001\n",
    "EPOCHS = 3\n",
    "MULTI_WORKERS_N = 1\n",
    "\n",
    "## Datasets\n",
    "SHADOW_DATA_PATH = f\"pickle/{dataset}/{model}/shadow.p\"\n",
    "EVALUATE_DATA_PATH = f\"pickle/{dataset}/{model}/eval.p\"\n",
    "# Save Dset create for attack model training\n",
    "ATT_TRAIN_DATA_PATH = f\"pickle/{dataset}/{model}/attack_train.p\"\n",
    "## Models\n",
    "SHADOW_MODEL_PATH = f\"shadow_models/{model}_shadow_{dataset_short}_overtrained.pth\"\n",
    "TARGET_MODEL_PATH = f\"models/{model}_{dataset}.pth\"\n",
    "ATTACK_MODEL_PATH = f\"attack_models/attack_{model_short}_{dataset_short}.pth\"\n",
    "\n",
    "DEVICE=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shadow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the shadow model trained in the other python script\n",
    "shadow_model = MODEL_MODULE(weights=None,num_classes=DATASET_ENUM.value).to(DEVICE) #resnet_target is the shadow model\n",
    "shadow_model.load_state_dict(torch.load(SHADOW_MODEL_PATH, map_location=DEVICE))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shadow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SHADOW_DATA_PATH, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "shadow_memb_data, shadow_non_memb_data = train_test_split(dataset, test_size=(1-0.5),shuffle=False)\n",
    "  \n",
    "shadow_membloader = DataLoader(shadow_memb_data, batch_size=1, shuffle=False, num_workers=1)\n",
    "shadow_non_membloader =  DataLoader(shadow_non_memb_data, batch_size=1, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Attack model training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack dataset was already established previosly, loading dataset from \"pickle/tinyimagenet/mobilenetv2/attack_train.p\".\n"
     ]
    }
   ],
   "source": [
    "attack_train_loader = create_shadow_post_train_loader(shadow_non_membloader, shadow_membloader, shadow_model, batch_size=64, \\\n",
    "    multi_n= MULTI_WORKERS_N, device=DEVICE, save_path=ATT_TRAIN_DATA_PATH, standardize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 1.5733,  1.0517,  0.9332]],  [[ 1.4803,  1.2408,  1.0936]],  [[ 1.8819,  1.4202,  0.9920]],  [[ 1.3752,  0.8301,  0.7765]],  [[ 0.6191,  0.4609,  0.4162]],  [[ 1.7589,  1.3028,  1.0077]],  [[ 1.7512,  1.6551,  1.4562]],  [[ 3.0344,  2.4331,  2.1334]],  [[ 0.8850,  0.8362,  0.6184]],  [[ 2.1119,  1.4899,  1.1929]],  [[ 1.5477,  0.9689,  0.3738]],  [[ 2.4597,  1.9625,  1.8480]],  [[ 2.1375,  1.5997,  1.3010]],  [[ 3.3657,  3.1185,  2.7974]],  [[ 3.3030,  2.5985,  1.6694]],  [[ 2.5688,  0.8300,  0.7213]],  [[ 4.4556,  3.3841,  3.3115]],  [[ 2.3506,  1.3098,  1.1554]],  [[ 1.4182,  0.6729,  0.2420]],  [[ 2.2486,  2.0390,  1.8939]],  [[ 2.3650,  2.2876,  1.8899]],  [[ 3.4936,  2.9939,  2.9636]],  [[ 3.8788,  3.2878,  3.0938]],  [[ 1.9715,  1.2318,  0.8861]],  [[ 2.2502,  1.8399,  1.8250]],  [[ 2.4132,  1.8050,  1.7030]],  [[ 1.5798,  1.4761,  1.2136]],  [[ 1.2507,  0.5630,  0.5377]],  [[ 1.3365,  1.0962,  0.8819]],  [[ 1.6777,  1.5569,  1.3446]],  [[ 3.2561,  3.2542,  2.0490]],  [[ 1.9250,  1.7088,  1.2930]],  [[ 0.8274,  0.0832, -0.2600]],  [[ 3.3547,  3.1570,  1.6173]],  [[ 0.2345, -0.1322, -0.3639]],  [[ 1.4679,  1.3514,  0.7325]],  [[ 1.8992,  1.6366,  1.1268]],  [[ 0.8980,  0.6110,  0.5559]],  [[ 2.5096,  2.4983,  1.7938]],  [[ 0.5770,  0.5422,  0.4812]],  [[ 2.7371,  2.4841,  2.4542]],  [[ 1.6427,  1.3581,  1.2954]],  [[ 1.5921,  1.4059,  1.3838]],  [[ 3.1852,  1.3478,  0.9721]],  [[ 4.3282,  4.1297,  3.5385]],  [[ 1.5452,  1.0282,  0.9898]],  [[ 2.8744,  1.7863,  1.0658]],  [[ 2.0610,  1.6146,  1.5584]],  [[ 1.7859,  1.1660,  1.0927]],  [[ 2.8089,  2.3414,  1.3514]],  [[ 2.6703,  2.6005,  1.9197]],  [[ 1.4963,  1.4459,  1.1786]],  [[ 6.0089,  5.8647,  5.3401]],  [[ 1.1760,  0.8220,  0.4815]],  [[ 6.0336,  5.8329,  5.2227]],  [[ 3.2623,  2.5365,  0.7838]],  [[ 1.3344,  1.1413,  0.9745]],  [[ 1.2265,  0.5182,  0.2900]],  [[ 2.8464,  2.3968,  2.3623]],  [[ 2.2005,  2.1898,  1.8202]],  [[ 1.3997,  1.2105,  0.9891]],  [[ 2.8689,  2.7174,  2.4708]],  [[ 0.7675,  0.4901, -0.1392]],  [[ 2.2065,  1.9917,  0.4991]]]), tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,  0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,  0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "attack_sample_iter = iter(attack_train_loader)\n",
    "print (str(next(attack_sample_iter)).replace('\\n',\"\").replace(\"   \",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallAttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallAttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.sigmoid(self.fc2(self.fc1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle Size Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleAttackNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiddleAttackNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)\n",
    "        self.fc5 = nn.Linear(16, 8)\n",
    "        self.bn5 = nn.BatchNorm1d(8)\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(torch.relu(self.bn5(self.fc5(x))))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target model\n",
    "target_model = MODEL_MODULE(weights=None,num_classes=DATASET_ENUM.value)\n",
    "target_model.load_state_dict (torch.load (TARGET_MODEL_PATH, map_location=DEVICE)[\"net\"])\n",
    "target_model.eval()\n",
    "target_model.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load **Evaluation Dataset** & get Posteriors/ Member Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------SAMPLE WINDOW---------------------------------------------------------\n",
      "Number Samples: 200\n",
      "Batchsize: 1\n",
      "Inputs:tensor([[[[0.9686, 0.9686, 0.9725,  ..., 0.9765, 0.9725, 0.9686], [0.9608, 0.9647, 0.9647,  ..., 0.9725, 0.9686, 0.9686], [0.9647, 0.9647, 0.9686,  ..., 0.9686, 0.9647, 0.9647], ..., [0.3843, 0.1294, 0.3294,  ..., 0.6627, 0.6980, 0.4980], [0.1333, 0.3804, 0.4118,  ..., 0.4078, 0.5020, 0.2902], [0.1569, 0.2863, 0.4353,  ..., 0.4510, 0.6549, 0.4078]],[[0.9765, 0.9765, 0.9804,  ..., 0.9843, 0.9804, 0.9765], [0.9686, 0.9725, 0.9725,  ..., 0.9804, 0.9765, 0.9765], [0.9725, 0.9725, 0.9765,  ..., 0.9765, 0.9725, 0.9725], ..., [0.3647, 0.1137, 0.3176,  ..., 0.5765, 0.6118, 0.4118], [0.1098, 0.3608, 0.4000,  ..., 0.3098, 0.4039, 0.1922], [0.1294, 0.2667, 0.4235,  ..., 0.3490, 0.5490, 0.3020]],[[0.9333, 0.9333, 0.9373,  ..., 0.9412, 0.9373, 0.9333], [0.9255, 0.9294, 0.9294,  ..., 0.9373, 0.9333, 0.9333], [0.9294, 0.9294, 0.9333,  ..., 0.9333, 0.9294, 0.9294], ..., [0.1451, 0.0000, 0.0157,  ..., 0.2392, 0.2745, 0.0745], [0.0000, 0.1412, 0.1216,  ..., 0.0471, 0.1451, 0.0000], [0.0000, 0.0510, 0.1608,  ..., 0.1255, 0.3333, 0.0863]]]])\n",
      "Labels:tensor([1])\n",
      "Outputs:tensor([[ 0.4925,0.7019,1.8541,2.6853,0.1122,0.4703,0.4657,1.5578,2.7969,0.2969, -0.0350,1.4328, -3.7095, -1.7368, -0.0616,0.6646,1.7536, -1.2033, -0.5835,1.4253,4.6648,1.0336, -2.4239,0.6449, -1.3258, -0.1582,0.6085,2.3937,2.6217, -1.2030, -4.5475, -2.1369, -1.6482,0.9976,4.9745,0.7253, -0.9326,2.6758, -3.0398,0.0841,2.0644, -0.3877,4.7155,2.6095, -0.8973, -0.2006, -2.2642, -1.8913,0.5155,5.2687,3.0943,2.8381, 13.5679,5.8385,3.2214, -1.2395,3.1005,3.3928,0.2908, -3.4924, -0.4880, -0.1672, -1.5264,0.2094,0.3934, -1.6441,4.9418, -0.1348,1.2011,3.5640, -0.4594, -2.7639,0.9806, -1.4823,0.3027,1.6067, -0.4682, -2.6888,2.3430,0.3176,0.0673,0.2947, -1.2473, -4.4172,3.8386, -0.5872, -2.3189, -1.9837, -2.2672,2.2100, -4.6268,2.6411, -1.7067, -1.1873, -1.2922,1.9940,0.1152, -1.2585,1.6353,2.5041, -1.9893,1.3272, -2.8423,3.2245, -0.7746, -2.2757, -2.0321,2.0781, -0.2510,0.8812, -0.8255,0.1134, -3.7675, -1.7079,5.4727,0.0395, -3.6180, -0.4509,3.8519,0.2185, -0.3826, -2.1689,0.9707, -1.4700, -2.2565, -1.9285, -1.5072, -3.1649, -0.5168,1.2508, -1.5264,2.1843, -1.1995, -0.6503, -1.1755, -2.4660, -1.7065, -1.0825, -4.3573,1.7748, -1.9619, -4.7868, -0.2399,3.0838, -1.7038, -0.2829,0.9655, -3.6001, -0.2558, -3.1754,0.1771, -2.9879,0.1816,1.0272,1.8759, -0.1429,0.7951, -0.8759,0.4756, -1.9061, -1.2312, -1.1019,2.9841, -2.6066,2.8457,0.8943, -1.6401, -0.1127, -0.5298, -2.3331,3.2348,4.6455, -1.6802,1.9260, -1.1920,0.6639, -0.0459, -1.5392,0.6645, -2.6598, -1.9408, -0.8512, -3.2321, -3.7985, -5.0127,1.3038, -2.0002, -1.3991, -1.4480, -3.3669, -0.1576, -1.1252,2.3770, -0.8301,4.9059,3.3771, -1.4965,2.3266,1.4266, -2.1473]])\n",
      "Top Sigmoids: tensor([[13.5679,  5.8385,  5.4727]])\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open(EVALUATE_DATA_PATH, \"rb\") as eval_f:\n",
    "    eval_dataset = pickle.load(eval_f)\n",
    "    # Create Posteriors with target model; MULTI_WORKERS_N defines workers num of returned DL\n",
    "    attack_eval_post_loader = create_eval_post_loader (target_model, eval_dataset, MULTI_WORKERS_N, DEVICE, test_dataset=False, standardize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(attack_eval_post_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attack Evaluation DL Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sample_iter = iter(attack_eval_post_loader)\n",
    "#print(str(next(eval_sample_iter)).replace('\\n',\"\").replace(\"   \",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack model state dictionary already available, loading into input model from attack_models/attack_mobilenet_tinyimage.pth!\n"
     ]
    }
   ],
   "source": [
    "attack_model = MiddleAttackNN()\n",
    "attack_model.to(DEVICE)\n",
    "# Further training Parameters \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(attack_model.parameters(), lr=LEARNING_R)\n",
    "# Do everything in one function\n",
    "# Train/ Load Attack model; For every epoch show epoch loss and evaluate\n",
    "train_or_load_and_eval_atck_model(attack_model, attack_train_loader, attack_eval_post_loader, optimizer, criterion, EPOCHS, ATTACK_MODEL_PATH, DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.92"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_attack_model(attack_model, attack_eval_post_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
